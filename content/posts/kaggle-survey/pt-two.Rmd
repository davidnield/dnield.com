---
markup: mmark
title: "The State of Data Science (Part 1)"
summary: "Results from the latest Kaggle Machine Learning & Data Science Survey (n = 19,717 respondents!)"
author: "David Nield"
date: 2019-11-19
output:
  blogdown::html_page:
    toc: true
categories: ["Kaggle"]
tags: ["survey analysis", "data visualization", "data science"]
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE)

require(pacman)
p_load(tidyverse, surveydata, gridExtra)

# Theme from edrub.in
theme_ed <- theme(
  legend.position = "bottom",
  panel.background = element_rect(fill = NA),
  panel.border = element_rect(fill = NA, color = "grey75"),
  axis.ticks = element_line(color = "grey95", size = 0.3),
  panel.grid.major = element_line(color = "grey95", size = 0.3),
  panel.grid.minor = element_line(color = "grey95", size = 0.3),
  legend.key = element_blank())

theme_ed_present <- theme(
  legend.position = "bottom",
  panel.background = element_rect(fill = NA),
  panel.border = element_rect(fill = NA, color = "grey75"),
  axis.ticks = element_line(color = "grey95", size = 0.3),
  panel.grid.major = element_line(color = "grey95", size = 0.3),
  panel.grid.minor = element_line(color = "grey95", size = 0.3),
  legend.key = element_blank(),
  text = element_text(size = 14),
  axis.text = element_text(size = 12))

# Taking median of an ordered factor
median.ordered <- function(x)
{
    levs <- levels(x)
    m <- median(as.integer(x), na.rm = TRUE)
    if(floor(m) != m)
    {
      warning("Median is between two values; using the first one")
      m <- floor(m)
    }
    ordered(m, labels = levs, levels = seq_along(levs))
}

# Gender Colors
gender_cols <- c("Male" = "#00BFC4",
                 "Female" = "#F8766D",
                 "Prefer not to say" = "#7CAE00",
                 "Prefer to self-describe" = "#C77CFF")

# Prep for cleaning language columns
cur_languages <- c("language_R",
              "language_python",
              "language_sql",
              "language_java",
              "language_C",
              "language_Cpp",
              "language_matlab")

common_languages <- c(
  "language_R",
  "language_python",
  "language_sql",
  "language_java",
  "language_c_cpp",
  "language_matlab")

vars <- c('year',
          'gender',
          'age',
          'education',
          'job_title',
          'yearly_compensation',
          'recommended_first_language',
          common_languages)

# Prepping 2019 data for merge
current <- read_csv("2019_cleaned.csv") %>% # reading in data
  mutate_at(cur_languages, # aggregating C and Cpp to a single C_Cpp column as in 2017 and 2018 data
            ~case_when(!is.na(.) ~ 1,
                       is.na(.) ~ 0)) %>% 
  mutate(language_c_cpp = case_when(language_C == 1 | language_Cpp == 1 ~ 1,
                                    language_C == 0 & language_Cpp == 0 ~ 0),
         yearly_compensation = case_when(
           yearly_compensation %in% c('$0-999',
                                      '1,000-1,999',
                                      '2,000-2,999',
                                      '3,000-3,999',
                                      '4,000-4,999',
                                      '5,000-7,499',
                                      '7,500-9,999') ~ '0 - 10,000',
           yearly_compensation %in% c('10,000-14,999',
                                      '15,000-19.999') ~ '10,000 - 20,000',
           yearly_compensation %in% c('20,000-24,999',
                                      '25,000-29,999') ~ '20,000 - 30,000',
           yearly_compensation == '30,000-39,999' ~ '30,000 - 40,000',
           yearly_compensation == '40,000-49,999' ~ '40,000 - 50,000',
           yearly_compensation == '50,000-59,999' ~ '50,000 - 60,000',
           yearly_compensation == '60,000-69,999' ~ '60,000 - 70,000',
           yearly_compensation == '70,000-79,999' ~ '70,000 - 80,000',
           yearly_compensation == '80,000-89,999' ~ '80,000 - 90,000',
           yearly_compensation == '90,000-99,999' ~ '90,000 - 100,000',
           yearly_compensation == '100,000-124,999' ~ '100,000 - 125,000',
           yearly_compensation == '125,000-149,999' ~ '125,000 - 150,000',
           yearly_compensation == '150,000-199,999' ~ '150,000 - 200,000',
           yearly_compensation == '200,000-249,999' ~ '200,000 - 250,000',
           yearly_compensation == '250,000-299,999' ~ '250,000 - 300,000',
           yearly_compensation == '300,000-500,000' ~ '300,000 - 500,000',
           yearly_compensation == '> $500,000' ~ '500,000+'),
         year = '2019') %>% 
  select(vars) # selecting variables of interest

# Prepping 2018 data for merge
oya <- read_csv("2018_multipleChoiceResponses.csv") %>% 
  rename(surveyduration = `Time from Start to Finish (seconds)`,
         gender = Q1,
         age = Q2,
         country_of_residence = Q3,
         education = Q4,
         job_title = Q6,
         yearly_compensation = Q9,
         language_python = Q16_Part_1,
         language_R = Q16_Part_2,
         language_sql = Q16_Part_3,
         language_java = Q16_Part_5,
         language_c_cpp = Q16_Part_8,
         language_matlab = Q16_Part_9,
         recommended_first_language = Q18) %>% 
  filter(!str_detect(surveyduration, "Duration"),
         country_of_residence == "United States of America") %>% 
  mutate_at(vars(starts_with("language_")),
            ~case_when(!is.na(.) ~ 1,
                       is.na(.) ~ 0)) %>% 
  mutate(age = case_when(age %in% c('70-79', '80+') ~ '70+',
                         TRUE ~ age),
         yearly_compensation = case_when(
           yearly_compensation == '0-10,000' ~ '0 - 10,000',
           yearly_compensation == '10-20,000' ~ '10,000 - 20,000',
           yearly_compensation == '20-30,000' ~ '20,000 - 30,000',
           yearly_compensation == '30-40,000' ~ '30,000 - 40,000',
           yearly_compensation == '40-50,000' ~ '40,000 - 50,000',
           yearly_compensation == '50-60,000' ~ '50,000 - 60,000',
           yearly_compensation == '60-70,000' ~ '60,000 - 70,000',
           yearly_compensation == '70-80,000' ~ '70,000 - 80,000',
           yearly_compensation == '80-90,000' ~ '80,000 - 90,000',
           yearly_compensation == '90-100,000' ~ '90,000 - 100,000',
           yearly_compensation == '100-125,000' ~ '100,000 - 125,000',
           yearly_compensation == '125-150,000' ~ '125,000 - 150,000',
           yearly_compensation == '150,000-200,000' ~ '150,000 - 200,000',
           yearly_compensation == '200-250,000' ~ '200,000 - 250,000',
           yearly_compensation == '250-300,000' ~ '250,000 - 300,000',
           yearly_compensation %in% c('300-400,000',
                                      '400-500,000') ~ '300,000 - 500,000',
           yearly_compensation == '500,000+' ~ '500,000+'),
         year = '2018') %>% 
  select(vars)

# Prepping 2017 data for merge
tya <- read_csv("2017_multipleChoiceResponses.csv") %>% 
  filter(Country == "United States",
         CompensationCurrency == "USD" | is.na(CompensationCurrency)) %>% 
  transmute(
    id = as.character(1:nrow(.)),
    gender = GenderSelect,
    country_of_residence = Country,
    compensation_currency = CompensationCurrency,
    age = Age,
    job_title = CurrentJobTitleSelect,
    recommended_first_language = LanguageRecommendationSelect,
    education = FormalEducation,
    yearly_compensation = CompensationAmount,
    work_tools = WorkToolsSelect) %>% 
  left_join(
    as_tibble(.) %>% 
      select(id, work_tools) %>% 
      mutate(work_tools = str_split(work_tools, pattern = ",")) %>% 
      unnest() %>%
      table() %>% 
      as_tibble() %>% 
      spread(work_tools, n)
  ) %>% 
  mutate(language_R = R,
         language_python = Python,
         language_sql = SQL,
         language_java = Java,
         language_c_cpp = `C/C++`,
         language_matlab = `MATLAB/Octave`) %>% 
  filter(age > 17) %>% 
  mutate(age = case_when(
    between(age, 18, 21) ~ '18-21',
    between(age, 22, 24) ~ '22-24',
    between(age, 25, 29) ~ '25-29',
    between(age, 30, 34) ~ '30-34',
    between(age, 35, 39) ~ '35-39',
    between(age, 40, 44) ~ '40-44',
    between(age, 45, 49) ~ '45-49',
    between(age, 50, 54) ~ '50-54',
    between(age, 55, 59) ~ '55-59',
    between(age, 60, 69) ~ '60-69',
    age >= 70 ~ '70+'),
    yearly_compensation = case_when(
    between(yearly_compensation, 0, 9999) ~ '0 - 10,000',
    between(yearly_compensation, 10000, 19999) ~ '10,000 - 20,000',
    between(yearly_compensation, 20000, 29999) ~ '20,000 - 30,000',
    between(yearly_compensation, 30000, 39999) ~ '30,000 - 40,000',
    between(yearly_compensation, 40000, 49999) ~ '40,000 - 50,000',
    between(yearly_compensation, 50000, 59999) ~ '50,000 - 60,000',
    between(yearly_compensation, 60000, 69999) ~ '60,000 - 70,000',
    between(yearly_compensation, 70000, 79999) ~ '70,000 - 80,000',
    between(yearly_compensation, 80000, 89999) ~ '80,000 - 90,000',
    between(yearly_compensation, 90000, 99999) ~ '90,000 - 100,000',
    between(yearly_compensation, 100000, 124999) ~ '100,000 - 125,000',
    between(yearly_compensation, 125000, 149999) ~ '125,000 - 150,000',
    between(yearly_compensation, 150000, 199999) ~ '150,000 - 200,000',
    between(yearly_compensation, 200000, 249999) ~ '200,000 - 250,000',
    between(yearly_compensation, 250000, 299999) ~ '250,000 - 300,000',
    between(yearly_compensation, 300000, 499999) ~ '300,000 - 500,000',
    yearly_compensation >= 500000 ~ '500,000+'),
         year = '2017') %>% 
  select(vars)


tsdata <- current %>% 
  bind_rows(oya) %>% 
  bind_rows(tya)

tsdata %>% 
  group_by(year) %>% 
  count(age) %>% 
  mutate(test = sum(n),
         prop = n/sum(n)) %>% 
  ungroup() %>% 
  ggplot(aes(x = year, y = prop, color = age, group = age, label = age)) +
  geom_line() +
  geom_label() +
  scale_y_continuous(label = scales::percent) +
  labs(x = "Year",
       y = "Percent") +
  theme_ed +
  theme(legend.position = "")



```

```{r unusedvars, include=FALSE}
# Unused 2018 Survey Vars ----
# surveyduration = `Time from Start to Finish (seconds)`,
# major = Q5,
# employer_industry = Q7,
# experience_role = Q8,
# company_ML_incorporation = Q10,
# role_influence_business_decisions = Q11_Part_1,
# role_build_ML_for_production = Q11_Part_2,
# role_build_or_run_data_infrastructure = Q11_Part_3,
# role_build_ML_prototypes = Q11_Part_4,
# role_ML_research = Q11_Part_5,
# role_none_of_above = Q11_Part_6,
# role_other = Q11_Part_7,
# primarytool = Q12_MULTIPLE_CHOICE,
# primarytool_basic = Q12_Part_1_TEXT,
# primarytool_advanced = Q12_Part_2_TEXT,
# primarytool_bi = Q12_Part_3_TEXT,
# primarytool_devenv = Q12_Part_4_TEXT,
# primarytool_cloud = Q12_Part_5_TEXT,
# ide_jupyter = Q13_Part_1,
# ide_rstudio = Q13_Part_2,
# ide_pycharm = Q13_Part_3,
# ide_visualstudiocode = Q13_Part_4,
# ide_nteract = Q13_Part_5,
# ide_atom = Q13_Part_6,
# ide_matlab = Q13_Part_7,
# ide_visualstudio = Q13_Part_8,
# ide_notepadpp = Q13_Part_9,
# ide_sublimetext = Q13_Part_10,
# ide_vim_emacs = Q13_Part_11,
# ide_intellij = Q13_Part_12,
# ide_spyder = Q13_Part_13,
# ide_none = Q13_Part_14,
# ide_other = Q13_Part_15,
# notebook_kaggle = Q14_Part_1,
# notebook_googlecolab = Q14_Part_2,
# notebook_msoft_azure = Q14_Part_3,
# notebook_domino = Q14_Part_4,
# notebook_googledatalab = Q14_Part_5,
# notebook_paperspace = Q14_Part_6,
# notebook_floydhub = Q14_Part_7,
# notebook_crestle = Q14_Part_8,
# notebook_binder_jupyterhub = Q14_Part_9,
# notebook_none = Q14_Part_10,
# notebook_other = Q14_Part_11,
# cloudcomputeplatform_gcp = Q15_Part_1,
# cloudcomputeplatform_aws = Q15_Part_2,
# cloudcomputeplatform_azure = Q15_Part_3,
# cloudcomputeplatform_ibm = Q15_Part_4,
# cloudcomputeplatform_alibaba = Q15_Part_5,
# cloudcomputeplatform_none = Q15_Part_6,
# cloudcomputeplatform_other = Q15_Part_7,
# primarylanguage = Q17,
# mlframeworks_sklearn = Q19_Part_1,
# mlframeworks_tensorflow = Q19_Part_2,
# mlframeworks_keras = Q19_Part_3,
# mlframeworks_pytorch = Q19_Part_4,
# mlframeworks_sparkmlib = Q19_Part_5,
# mlframeworks_h2o = Q19_Part_6,
# mlframeworks_fastai = Q19_Part_7,
# mlframeworks_mxnet = Q19_Part_8,
# mlframeworks_caret = Q19_Part_9,
# mlframeworks_xgboost = Q19_Part_10,
# mlframeworks_mlr = Q19_Part_11,
# mlframeworks_prophet = Q19_Part_12,
# mlframeworks_randomforest = Q19_Part_13,
# mlframeworks_lightgbm = Q19_Part_14,
# mlframeworks_catboost = Q19_Part_15,
# mlframeworks_cntk = Q19_Part_16,
# mlframeworks_caffe = Q19_Part_17,
# mlframeworks_none = Q19_Part_18,
# mlframeworks_other = Q19_Part_19,
# primary_ml_library = Q20,
# datavizlib_ggplot = Q21_Part_1,
# datavizlib_matplotlib = Q21_Part_2,
# datavizlib_altair = Q21_Part_3,
# datavizlib_shiny = Q21_Part_4,
# datavizlib_d3 = Q21_Part_5,
# datavizlib_plotly = Q21_Part_6,
# datavizlib_bokeh = Q21_Part_7,
# datavizlib_seaborn = Q21_Part_8,
# datavizlib_geoplotlib = Q21_Part_9,
# datavizlib_leaflet = Q21_Part_10,
# datavizlib_lattice = Q21_Part_11,
# datavizlib_none = Q21_Part_12,
# datavizlib_other = Q21_Part_13,
# primary_dataviz_library = Q22,
# pct_time_coding = Q23,
# experience_data = Q24,
# experience_ml = Q25,
# consider_self_datasci = Q26,
# cloudcomputeproduct_ec2 = Q27_Part_1,
# cloudcomputeproduct_gce = Q27_Part_2,
# cloudcomputeproduct_awselasticbeanstalk = Q27_Part_3,
# cloudcomputeproduct_googleappengine = Q27_Part_4,
# cloudcomputeproduct_googlekubernetes = Q27_Part_5,
# cloudcomputeproduct_lambda = Q27_Part_6,
# cloudcomputeproduct_googlecloudfunctions = Q27_Part_7,
# cloudcomputeproduct_awsbatch = Q27_Part_8,
# cloudcomputeproduct_azurevm = Q27_Part_9,
# cloudcomputeproduct_azurecontainer = Q27_Part_10,
# cloudcomputeproduct_azurefunctions = Q27_Part_11,
# cloudcomputeproduct_azureeventgrid = Q27_Part_12,
# cloudcomputeproduct_azurebatch = Q27_Part_13,
# cloudcomputeproduct_azurekubernetes = Q27_Part_14,
# cloudcomputeproduct_ibmvirtualservers = Q27_Part_15,
# cloudcomputeproduct_ibmcontainer = Q27_Part_16,
# cloudcomputeproduct_ibmkubernetes = Q27_Part_17,
# cloudcomputeproduct_ibmcloudfoundry = Q27_Part_18,
# cloudcomputeproduct_none = Q27_Part_19,
# cloudcomputeproduct_other = Q27_Part_20,
# mlproduct_amazontranscribe = Q28_Part_1,
# mlproduct_googlecloudspeechtotext = Q28_Part_2,
# mlproduct_amazonrekognition = Q28_Part_3,
# mlproduct_googlecloudvision = Q28_Part_4,
# mlproduct_amazoncomprehend = Q28_Part_5,
# mlproduct_googlecloudnaturallanguage = Q28_Part_6,
# mlproduct_amazontranslate = Q28_Part_7,
# mlproduct_googlecloudtranslation = Q28_Part_8,
# mlproduct_amazonlex = Q28_Part_9,
# mlproduct_googlediagflow = Q28_Part_10,
# mlproduct_amazonrekognitionvideo = Q28_Part_11,
# mlproduct_googlecloudvideointelligence = Q28_Part_12,
# mlproduct_googleautoml = Q28_Part_13,
# mlproduct_sagemaker = Q28_Part_14,
# mlproduct_googlecloudmlengine = Q28_Part_15,
# mlproduct_datarobot = Q28_Part_16,
# mlproduct_h20driverless = Q28_Part_17,
# mlproduct_dominodatalab = Q28_Part_18,
# mlproduct_sas = Q28_Part_19,
# mlproduct_dataiku = Q28_Part_20,
# mlproduct_rapidminer = Q28_Part_21,
# mlproduct_instabase = Q28_Part_22,
# mlproduct_algorithmia = Q28_Part_23,
# mlproduct_dataversity = Q28_Part_24,
# mlproduct_cloudera = Q28_Part_25,
# mlproduct_azuremlstudio = Q28_Part_26,
# mlproduct_azuremlworkbench = Q28_Part_27,
# mlproduct_azurecortanaintelligencesuite = Q28_Part_28,
# mlproduct_azurebingspeech = Q28_Part_29,
# mlproduct_azurespeakerrecognition = Q28_Part_30,
# mlproduct_azurecomputervision = Q28_Part_31,
# mlproduct_azureface = Q28_Part_32,
# mlproduct_azurevideo = Q28_Part_33,
# mlproduct_ibmwatsonstudio = Q28_Part_34,
# mlproduct_ibmwatsonknowledgecatalog = Q28_Part_35,
# mlproduct_ibmwatsonassistant = Q28_Part_36,
# mlproduct_ibmwatsondiscovery = Q28_Part_37,
# mlproduct_ibmwatsontts = Q28_Part_38,
# mlproduct_ibmwatsonvisualrecognition = Q28_Part_39,
# mlproduct_ibmwatsonml = Q28_Part_40,
# mlproduct_azurecognitiveservices = Q28_Part_41,
# mlproduct_none = Q28_Part_42,
# mlproduct_other = Q28_Part_43,
# dbproduct_awsrelationaldbs = Q29_Part_1,
# dbproduct_awsaurora = Q29_Part_2,
# dbproduct_googlecloudsql = Q29_Part_3,
# dbproduct_googlecloudspanner = Q29_Part_4,
# dbproduct_awsdynamodb = Q29_Part_5,
# dbproduct_googleclouddatastore = Q29_Part_6,
# dbproduct_googlecloudbigtable = Q29_Part_7,
# dbproduct_awssimpledb = Q29_Part_8,
# dbproduct_msoftsql = Q29_Part_9,
# dbproduct_mysql = Q29_Part_10,
# dbproduct_postgressql = Q29_Part_11,
# dbproduct_sqllite = Q29_Part_12,
# dbproduct_oracledb = Q29_Part_13,
# dbproduct_ingres = Q29_Part_14,
# dbproduct_msoftaccess = Q29_Part_15,
# dbproduct_nexusdb = Q29_Part_16,
# dbproduct_sapiq = Q29_Part_17,
# dbproduct_googlefusiontables = Q29_Part_18,
# dbproduct_azuremysql = Q29_Part_19,
# dbproduct_azurecosmosdb = Q29_Part_20,
# dbproduct_azuresqldb = Q29_Part_21,
# dbproduct_azurepostgresql = Q29_Part_22,
# dbproduct_ibmcloudcompose = Q29_Part_23,
# dbproduct_ibmcloudcomposemysql = Q29_Part_24,
# dbproduct_ibmcloudcomposepostgresql = Q29_Part_25,
# dbproduct_ibmclouddb2 = Q29_Part_26,
# dbproduct_none = Q29_Part_27,
# dbproduct_other = Q29_Part_28,
# bigdataproduct_elasticmapreduce = Q30_Part_1,
# bigdataproduct_awsbatch = Q30_Part_2,
# bigdataproduct_googleclouddataproc = Q30_Part_3,
# bigdataproduct_googleclouddataflow = Q30_Part_4,
# bigdataproduct_googleclouddataprep = Q30_Part_5,
# bigdataproduct_awskinesis = Q30_Part_6,
# bigdataproduct_googlecloudpubsub = Q30_Part_7,
# bigdataproduct_athena = Q30_Part_8,
# bigdataproduct_redshift = Q30_Part_9,
# bigdataproduct_bigquery = Q30_Part_10,
# bigdataproduct_teradata = Q30_Part_11,
# bigdataproduct_msoftanalysis = Q30_Part_12,
# bigdataproduct_oracleexadata = Q30_Part_13,
# bigdataproduct_oraclewarehousebuiderl = Q30_Part_14,
# bigdataproduct_sapiq = Q30_Part_15,
# bigdataproduct_snowflake = Q30_Part_16,
# bigdataproduct_databricks = Q30_Part_17,
# bigdataproduct_azuresqldatawarehouse = Q30_Part_18,
# bigdataproduct_azurehdinsight = Q30_Part_19,
# bigdataproduct_azurestreamanalytics = Q30_Part_20,
# bigdataproduct_ibminfospheredatastorage = Q30_Part_21,
# bigdataproduct_ibmcloudanalyticsengine = Q30_Part_22,
# bigdataproduct_ibmcloudstreaminganalytics = Q30_Part_23,
# bigdataproduct_none = Q30_Part_24,
# bigdataproduct_other = Q30_Part_25,
# datatypes_audio = Q31_Part_1,
# datatypes_categorical = Q31_Part_2,
# datatypes_genetic = Q31_Part_3,
# datatypes_geospatial = Q31_Part_4,
# datatypes_image = Q31_Part_5,
# datatypes_numeric = Q31_Part_6,
# datatypes_sensor = Q31_Part_7,
# datatypes_tabular = Q31_Part_8,
# datatypes_text = Q31_Part_9,
# datatypes_timeseries = Q31_Part_10,
# datatypes_video = Q31_Part_11,
# datatypes_other = Q31_Part_12,
# primary_datatype = Q32,
# publicdatasource_govt = Q33_Part_1,
# publicdatasource_universityresearchgroups = Q33_Part_2,
# publicdatasource_nonprofitresearchgroups = Q33_Part_3,
# publicdatasource_dataaggregators = Q33_Part_4,
# publicdatasource_selfcollect = Q33_Part_5,
# publicdatasource_publicdatafromprivatecompanies = Q33_Part_6,
# publicdatasource_googlesearch = Q33_Part_7,
# publicdatasource_googledatasetsearch = Q33_Part_8,
# publicdatasource_github = Q33_Part_9,
# publicdatasource_none = Q33_Part_10,
# publicdatasource_other = Q33_Part_11,
# analysisshare_gathering = Q34_Part_1,
# analysisshare_cleaning = Q34_Part_2,
# analysisshare_visualizing = Q34_Part_3,
# analysisshare_modelbuilding = Q34_Part_4,
# analysisshare_modelimplementation = Q34_Part_5,
# analysisshare_communicatinginsights = Q34_Part_6,
# trainingshare_selftaught = Q35_Part_1,
# trainingshare_onlinecourse = Q35_Part_2,
# trainingshare_work = Q35_Part_3,
# trainingshare_university= Q35_Part_4,
# trainingshare_kaggle = Q35_Part_5,
# trainingshare_other = Q35_Part_6,
# datascicourses_udacity = Q36_Part_1,
# datascicourses_coursera = Q36_Part_2,
# datascicourses_edx = Q36_Part_3,
# datascicourses_datacamp = Q36_Part_4,
# datascicourses_dataquest = Q36_Part_5,
# datascicourses_kaggle = Q36_Part_6,
# datascicourses_fastai = Q36_Part_7,
# datascicourses_googledevs = Q36_Part_8,
# datascicourses_udemy = Q36_Part_9,
# datascicourses_theschoolai = Q36_Part_10,
# datascicourses_university = Q36_Part_11,
# datascicourses_none = Q36_Part_12,
# datascicourses_other = Q36_Part_13,
# primary_datascicourse = Q37,
# datascimedia_twitter = Q38_Part_1,
# datascimedia_hackernews = Q38_Part_2,
# datascimedia_reddit = Q38_Part_3,
# datascimedia_kaggleforum = Q38_Part_4,
# datascimedia_fastaiforum = Q38_Part_5,
# datascimedia_siraj = Q38_Part_6,
# datascimedia_datatau = Q38_Part_7,
# datascimedia_lineardisgressions = Q38_Part_8,
# datascimedia_cloudaiadventures = Q38_Part_9,
# datascimedia_fivethirtyeight = Q38_Part_10,
# datascimedia_arxiv = Q38_Part_11,
# datascimedia_journalpubs = Q38_Part_12,
# datascimedia_fastmlblog = Q38_Part_13,
# datascimedia_kdnuggets = Q38_Part_14,
# datascimedia_oreilly = Q38_Part_15,
# datascimedia_partiallyderivative = Q38_Part_16,
# datascimedia_dataskeptic = Q38_Part_17,
# datascimedia_medium = Q38_Part_18,
# datascimedia_towardsdatasci = Q38_Part_19,
# datascimedia_analyticsvidhya = Q38_Part_20,
# datascimedia_none = Q38_Part_21,
# datascimedia_other = Q38_Part_22,
# quality_onlineplatforms = Q39_Part_1,
# quality_bootcamps = Q39_Part_2,
# academicachive_or_indprojects = Q40,
# importance_unfairbias = Q41_Part_1,
# importance_explainability = Q41_Part_2,
# importance_reproducibility = Q41_Part_3,
# metrics_revenue = Q42_Part_1,
# metrics_accuracy = Q42_Part_2,
# metrics_unfairbias = Q42_Part_3,
# metrics_na = Q42_Part_4,
# metrics_other = Q42_Part_5,
# share_explore_unfair_bias = Q43,
# unfairbiasdifficulty_collection_analysis_disconnect = Q44_Part_1,
# unfairbiasdifficulty_identifying_targeted_group = Q44_Part_2,
# unfairbiasdifficulty_data_quantity_targeted_group = Q44_Part_3,
# unfairbiasdifficulty_identifying_eval_metrics = Q44_Part_4,
# unfairbiasdifficulty_never_found_difficult = Q44_Part_5,
# unfairbiasdifficulty_never_performed_task = Q44_Part_6,
# whenexploremodel_important_production_model = Q45_Part_1,
# whenexploremodel_production_implementation = Q45_Part_2,
# whenexploremodel_evaluating_model_for_production = Q45_Part_3,
# whenexploremodel_model_designed_for_insights = Q45_Part_4,
# whenexploremodel_first_exploring_model_dataset = Q45_Part_5,
# whenexploremodel_do_not_explore_interpret_model = Q45_Part_6,
# share_explore_model_insights = Q46,
# modelinterpretationmetrics_individual_coefficients = Q47_Part_1,
# modelinterpretationmetrics_feature_correlations = Q47_Part_2,
# modelinterpretationmetrics_feature_importance = Q47_Part_3,
# modelinterpretationmetrics_decision_boundaries = Q47_Part_4,
# modelinterpretationmetrics_partial_dependence_plots = Q47_Part_5,
# modelinterpretationmetrics_dimension_reduction = Q47_Part_6,
# modelinterpretationmetrics_attention_mapping = Q47_Part_7,
# modelinterpretationmetrics_plot_predicted_vs_actual = Q47_Part_8,
# modelinterpretationmetrics_print_decision_tree = Q47_Part_9,
# modelinterpretationmetrics_sensitivity_analysis = Q47_Part_10,
# modelinterpretationmetrics_lime_functions = Q47_Part_11,
# modelinterpretationmetrics_eli5_functions = Q47_Part_12,
# modelinterpretationmetrics_shap_functions = Q47_Part_13,
# modelinterpretationmetrics_none = Q47_Part_14,
# modelinterpretationmetrics_other = Q47_Part_15,
# modelinterpretationmetrics_other_text = Q47_Part_16,
# consider_ml_methods_black_boxes = Q48,
# reproducabilitytools_github_code = Q49_Part_1,
# reproducabilitytools_github_code_and_data = Q49_Part_2,
# reproducabilitytools_hosted_service = Q49_Part_3,
# reproducabilitytools_containers = Q49_Part_4,
# reproducabilitytools_virtual_machines = Q49_Part_5,
# reproducabilitytools_document_code = Q49_Part_6,
# reproducabilitytools_readable_code = Q49_Part_7,
# reproducabilitytools_define_random_seeds = Q49_Part_8,
# reproducabilitytools_relative_file_paths = Q49_Part_9,
# reproducabilitytools_dependency_text_file = Q49_Part_10,
# reproducabilitytools_none = Q49_Part_11,
# reproducabilitytools_other = Q49_Part_12,
# reproducabilitybarriers_expensive = Q50_Part_1,
# reproducabilitybarriers_timeconsuming = Q50_Part_2,
# reproducabilitybarriers_tootechnical = Q50_Part_3,
# reproducabilitybarriers_afraidoftheft = Q50_Part_4,
# reproducabilitybarriers_noincentive = Q50_Part_5,
# reproducabilitybarriers_neverconsideredit = Q50_Part_6,
# reproducabilitybarriers_noneofabove = Q50_Part_7,
# reproducabilitybarriers_other = Q50_Part_8
# language_bash = Q16_Part_4,
# language_javascript_typescript = Q16_Part_6,
# language_visualbasic = Q16_Part_7,
# language_scala = Q16_Part_10,
# language_julia = Q16_Part_11,
# language_go = Q16_Part_12,
# language_csharp_dotnet = Q16_Part_13,
# language_php = Q16_Part_14,
# language_ruby = Q16_Part_15,
# language_sas_stata = Q16_Part_16,
# language_none = Q16_Part_17,
# language_other = Q16_Part_18)

# Unused 2017 Survey Vars ----
# employment_status = EmploymentStatus,
    # student_status = StudentStatus,
    # employer_industry = EmployerIndustry,
    # publicdatasource = PublicDatasetsSelect,
    # learningplatform = LearningPlatformSelect,
    # datascimedia = BlogsPodcastsNewslettersSelect,
    # datascicourses = CoursePlatformSelect,
    # major = MajorSelect,
```


---
markup: mmark
title: "The State of Data Science (Part 3)"
summary: "What is a Data Scientist?"
author: "David Nield"
date: 2019-11-19
output:
  blogdown::html_page:
    toc: true
categories: ["Kaggle"]
tags: ["survey analysis", "data visualization", "data science"]
---

Today let's settle the question: what is a data scientist exactly?

To settle that question, we're essentially going to answer a related question: who is a data scientist? To do this, I'm going to train a classification model on our survey data from part 1 to figure out what are the traits that predict whether a respondent is a data scientist as opposed to some other category.

I'll leave the nitty gritty details and code for the data cleaning and feature engineering at the end for everyone interested.

The first data cleaning step was to rename all of the variable names from "Q1", "Q2", etc. to something more descriptive and useful. This was done manually and was pretty tedious, but it'll turn out to be useful not just for documentation purposes but also for feature engineering down the road. 

```{r showing format of data}
require(pacman)
p_load(tidyverse, caret)

kaggle <- read_csv("2019_multiple_choice_responses.csv") %>% 
  rename(surveyduration = `Time from Start to Finish (seconds)`,
         age = Q1,
         gender = Q2,
         gender_other_text = Q2_OTHER_TEXT,
         country_of_residence = Q3,
         education = Q4,
         job_title = Q5,
         job_title_other_text = Q5_OTHER_TEXT,
         company_size = Q6,
         datasci_team_size = Q7,
         company_ML_incorporation = Q8,
         role_influence_business_decisions = Q9_Part_1,
         role_build_or_run_data_infrastructure = Q9_Part_2,
         role_build_ML_prototypes = Q9_Part_3,
         role_build_ML_for_production = Q9_Part_4,
         role_improve_existing_ML_models = Q9_Part_5,
         role_ML_research = Q9_Part_6,
         role_none_of_above = Q9_Part_7,
         role_other = Q9_Part_8,
         role_other_text = Q9_OTHER_TEXT,
         yearly_compensation = Q10,
         amt_spent_ML_cloud_products_last5years = Q11,
         datascimedia_twitterdatasciinfluencers = Q12_Part_1,
         datascimedia_hackernews = Q12_Part_2,
         datascimedia_reddit = Q12_Part_3,
         datascimedia_kaggle = Q12_Part_4,
         datascimedia_courseforums = Q12_Part_5,
         datascimedia_youtube = Q12_Part_6,
         datascimedia_podcasts = Q12_Part_7,
         datascimedia_blogs = Q12_Part_8,
         datascimedia_journalpubs = Q12_Part_9,
         datascimedia_slack = Q12_Part_10,
         datascimedia_none = Q12_Part_11,
         datascimedia_other = Q12_Part_12,
         datascimedia_other_text = Q12_OTHER_TEXT,
         datascicourses_udacity = Q13_Part_1,
         datascicourses_coursera = Q13_Part_2,
         datascicourses_edx = Q13_Part_3,
         datascicourses_datacamp = Q13_Part_4,
         datascicourses_dataquest = Q13_Part_5,
         datascicourses_kaggle = Q13_Part_6,
         datascicourses_fastai = Q13_Part_7,
         datascicourses_udemy = Q13_Part_8,
         datascicourses_linkedin = Q13_Part_9,
         datascicourses_university = Q13_Part_10,
         datascicourses_none = Q13_Part_11,
         datascicourses_other = Q13_Part_12,
         datascicourses_other_text = Q13_OTHER_TEXT,
         primarytool = Q14,
         primarytool_basic = Q14_Part_1_TEXT,
         primarytool_advanced = Q14_Part_2_TEXT,
         primarytool_bi = Q14_Part_3_TEXT,
         primarytool_devenv = Q14_Part_4_TEXT,
         primarytool_cloud = Q14_Part_5_TEXT,
         primarytool_other = Q14_OTHER_TEXT,
         experience_data = Q15,
         ide_jupyter = Q16_Part_1,
         ide_rstudio = Q16_Part_2,
         ide_pycharm = Q16_Part_3,
         ide_atom = Q16_Part_4,
         ide_matlab = Q16_Part_5,
         ide_visualstudio = Q16_Part_6,
         ide_spyder = Q16_Part_7,
         ide_vim_emacs = Q16_Part_8,
         ide_notepadpp = Q16_Part_9,
         ide_sublimetext = Q16_Part_10,
         ide_none = Q16_Part_11,
         ide_other = Q16_Part_12,
         ide_other_text = Q16_OTHER_TEXT,
         notebook_kaggle = Q17_Part_1,
         notebook_googlecolab = Q17_Part_2,
         notebook_msoft_azure = Q17_Part_3,
         notebook_googlecloud = Q17_Part_4,
         notebook_paperspace = Q17_Part_5,
         notebook_floydhub = Q17_Part_6,
         notebook_binder_jupyterhub = Q17_Part_7,
         notebook_watson_studio = Q17_Part_8,
         notebook_codeocean = Q17_Part_9,
         notebook_aws = Q17_Part_10,
         notebook_none = Q17_Part_11,
         notebook_other = Q17_Part_12,
         notebook_other_text = Q17_OTHER_TEXT,
         language_python = Q18_Part_1,
         language_R = Q18_Part_2,
         language_sql = Q18_Part_3,
         language_C = Q18_Part_4,
         language_Cpp = Q18_Part_5,
         language_java = Q18_Part_6,
         language_javascript = Q18_Part_7,
         language_typescript = Q18_Part_8,
         language_bash = Q18_Part_9,
         language_matlab = Q18_Part_10,
         language_none = Q18_Part_11,
         language_other = Q18_Part_12,
         language_other_text = Q18_OTHER_TEXT,
         recommend_first_language = Q19,
         recommend_first_language_other_text = Q19_OTHER_TEXT,
         datavizlib_ggplot = Q20_Part_1,
         datavizlib_matplotlib = Q20_Part_2,
         datavizlib_altair = Q20_Part_3,
         datavizlib_shiny = Q20_Part_4,
         datavizlib_d3js = Q20_Part_5,
         datavizlib_plotly = Q20_Part_6,
         datavizlib_bokeh = Q20_Part_7,
         datavizlib_seaborn = Q20_Part_8,
         datavizlib_geoplotlib = Q20_Part_9,
         datavizlib_leaflet = Q20_Part_10,
         datavizlib_none = Q20_Part_11,
         datavizlib_other = Q20_Part_12,
         dataviz_other_text = Q20_OTHER_TEXT,
         hardware_cpu = Q21_Part_1,
         hardware_gpu = Q21_Part_2,
         hardware_tpu = Q21_Part_3,
         hardware_none_idk = Q21_Part_4,
         hardware_other = Q21_Part_5,
         hardware_other_text = Q21_OTHER_TEXT,
         ever_used_tpu = Q22,
         experience_ml = Q23,
         mlalgs_regression = Q24_Part_1,
         mlalgs_trees = Q24_Part_2,
         mlalgs_boosting = Q24_Part_3,
         mlalgs_bayes = Q24_Part_4,
         mlalgs_evolutionary = Q24_Part_5,
         mlalgs_denseneuralnets = Q24_Part_6,
         mlalgs_cnn = Q24_Part_7,
         mlalgs_gan = Q24_Part_8,
         mlalgs_rnn = Q24_Part_9,
         mlalgs_transnets = Q24_Part_10,
         mlalgs_none = Q24_Part_11,
         mlalgs_other = Q24_Part_12,
         mlalgs_other_text = Q24_OTHER_TEXT,
         mltools_aug = Q25_Part_1,
         mltools_feateng = Q25_Part_2,
         mltools_modelselect = Q25_Part_3,
         mltools_archsearch = Q25_Part_4,
         mltools_tuning = Q25_Part_5,
         mltools_fullmlpipelines = Q25_Part_6,
         mltools_none = Q25_Part_7,
         mltools_other = Q25_Part_8,
         mltools_other_text = Q25_OTHER_TEXT,
         compvisionmethods_genpurpose = Q26_Part_1,
         compvisionmethods_segmentation = Q26_Part_2,
         compvisionmethods_detection = Q26_Part_3,
         compvisionmethods_classification = Q26_Part_4,
         compvisionmethods_generativenets = Q26_Part_5,
         compvisionmethods_none = Q26_Part_6,
         compvisionmethods_other = Q26_Part_7,
         compvisionmethods_other_text = Q26_OTHER_TEXT,
         nlpmethods_wordembedding = Q27_Part_1,
         nlpmethods_encodersdecoders = Q27_Part_2,
         nlpmethods_contextembedding = Q27_Part_3,
         nlpmethods_transformermodels = Q27_Part_4,
         nlpmethods_none = Q27_Part_5,
         nlpmethods_other = Q27_Part_6,
         nlpmethods_other_text = Q27_OTHER_TEXT,
         mlframeworks_sklearn = Q28_Part_1,
         mlframeworks_tensorflow = Q28_Part_2,
         mlframeworks_keras = Q28_Part_3,
         mlframeworks_randomforest = Q28_Part_4,
         mlframeworks_xgboost = Q28_Part_5,
         mlframeworks_pytorch = Q28_Part_6,
         mlframeworks_caret = Q28_Part_7,
         mlframeworks_lightgbm = Q28_Part_8,
         mlframeworks_sparkmlib = Q28_Part_9,
         mlframeworks_fastai = Q28_Part_10,
         mlframeworks_none = Q28_Part_11,
         mlframeworks_other = Q28_Part_12,
         mlframeworks_other_text = Q28_OTHER_TEXT,
         cloudcomputeplatform_gcp = Q29_Part_1,
         cloudcomputeplatform_aws = Q29_Part_2,
         cloudcomputeplatform_azure = Q29_Part_3,
         cloudcomputeplatform_ibm = Q29_Part_4,
         cloudcomputeplatform_alibaba = Q29_Part_5,
         cloudcomputeplatform_salesforce = Q29_Part_6,
         cloudcomputeplatform_oracle = Q29_Part_7,
         cloudcomputeplatform_sap = Q29_Part_8,
         cloudcomputeplatform_vmware = Q29_Part_9,
         cloudcomputeplatform_redhat = Q29_Part_10,
         cloudcomputeplatform_none = Q29_Part_11,
         cloudcomputeplatform_other = Q29_Part_12,
         cloudcomputeplatform_other_text = Q29_OTHER_TEXT,
         cloudcomputeproduct_ec2 = Q30_Part_1,
         cloudcomputeproduct_gce = Q30_Part_2,
         cloudcomputeproduct_lambda = Q30_Part_3,
         cloudcomputeproduct_azurevm = Q30_Part_4,
         cloudcomputeproduct_googleappengine = Q30_Part_5,
         cloudcomputeproduct_googlecloudfunctions = Q30_Part_6,
         cloudcomputeproduct_awselasticbeanstalk = Q30_Part_7,
         cloudcomputeproduct_googlekubernetes = Q30_Part_8,
         cloudcomputeproduct_awsbatch = Q30_Part_9,
         cloudcomputeproduct_azurecontainer = Q30_Part_10,
         cloudcomputeproduct_none = Q30_Part_11,
         cloudcomputeproduct_other = Q30_Part_12,
         cloudcomputeproduct_other_text = Q30_OTHER_TEXT,
         bigdataproduct_bigquery = Q31_Part_1,
         bigdataproduct_redshift = Q31_Part_2,
         bigdataproduct_databricks = Q31_Part_3,
         bigdataproduct_elasticmapreduce = Q31_Part_4,
         bigdataproduct_teradata = Q31_Part_5,
         bigdataproduct_msoftanalysis = Q31_Part_6,
         bigdataproduct_googleclouddataflow = Q31_Part_7,
         bigdataproduct_athena = Q31_Part_8,
         bigdataproduct_kinesis = Q31_Part_9,
         bigdataproduct_googlecloudpubsub = Q31_Part_10,
         bigdataproduct_none = Q31_Part_11,
         bigdataproduct_other = Q31_Part_12,
         bigdataproduct_other_text = Q31_OTHER_TEXT,
         mlproduct_sas = Q32_Part_1,
         mlproduct_cloudera = Q32_Part_2,
         mlproduct_azuremlstudio = Q32_Part_3,
         mlproduct_googlecloudmlengine = Q32_Part_4,
         mlproduct_googlecloudvision = Q32_Part_5,
         mlproduct_googlecloudspeechtotext = Q32_Part_6,
         mlproduct_googlecloudnaturallanguage = Q32_Part_7,
         mlproduct_rapidminer = Q32_Part_8,
         mlproduct_googlecloudtranslation = Q32_Part_9,
         mlproduct_sagemaker = Q32_Part_10,
         mlproduct_none = Q32_Part_11,
         mlproduct_other = Q32_Part_12,
         mlproduct_other_text = Q32_OTHER_TEXT,
         automltools_googleautoml = Q33_Part_1,
         automltools_h20driverless = Q33_Part_2,
         automltools_databricksautoml = Q33_Part_3,
         automltools_datarobotautoml = Q33_Part_4,
         automltools_tpot = Q33_Part_5,
         automltools_autokeras = Q33_Part_6,
         automltools_autosklearn = Q33_Part_7,
         automltools_auto_ml = Q33_Part_8,
         automltools_xcessiv = Q33_Part_9,
         automltools_mlbox = Q33_Part_10,
         automltools_none = Q33_Part_11,
         automltools_other = Q33_Part_12,
         automltools_other_text = Q33_OTHER_TEXT,
         dbproduct_mysql = Q34_Part_1,
         dbproduct_postgressql = Q34_Part_2,
         dbproduct_sqllite = Q34_Part_3,
         dbproduct_msoftsql = Q34_Part_4,
         dbproduct_oracledb = Q34_Part_5,
         dbproduct_msoftaccess = Q34_Part_6,
         dbproduct_awsrelationaldbs = Q34_Part_7,
         dbproduct_awsdynamodb = Q34_Part_8,
         dbproduct_azuresqldb = Q34_Part_9,
         dbproduct_googlecloudsql = Q34_Part_10,
         dbproduct_none = Q34_Part_11,
         dbproduct_other = Q34_Part_12,
         dbproduct_other_text = Q34_OTHER_TEXT
         )
```

You can see that we have an incredible amount of variables here, 246 to be exact. 

But there weren't 246 questions on the survey: these variables are in a wide format with respect to the "Check all the apply" questions, which I grouped together by using the same prefix (e.g. "role_") for variables associated with the same question.

Let's take a glimpse at the data.

```{r glimpsingdata}
kaggle
```

Here we see that the first row contains the text of the question, not responses. Let's drop that. We could use `kaggle[-1,]` but I'm not a fan of dropping rows via indexing, just in case the line gets accidentally run more than once and the top row keeps getting shaved off. Let's make a more explicit filter based on text in the first row to drop it. While we're at it, let's filter to Americans to be consistent with Part 1 of this series.

```{r filteringdata}
kaggle <- kaggle %>% 
  filter(!str_detect(surveyduration, "Duration"),
         country_of_residence == "United States of America")

kaggle
```

Much better.

```{r peaking at data}
unique(kaggle$role_influence_business_decisions)
```

Looking at the unique values for these "check all the apply" questions, you can see that a "Checked" response is represented by the text of the response, while leaving it "Unchecked" is represented as an null value. Let's take these variables and convert them to dummy variables.

To do this, I'm going to write a function I'm going to call "dummyify" that just converts non-null values to 1 and null values to 0 and apply with a "mutate_at" that points to the prefixed variables. This is where the renaming is already helping!

```{r dummyingvariables}
dummyify <- function(x) {
  case_when(
      !is.na(x) ~ 1,
      is.na(x) ~ 0
    )
}

kaggle <- kaggle %>% 
  mutate_at(
    vars(c(
      starts_with("role_"),
      starts_with("datascicourse_"),
      starts_with("ide_"), 
      starts_with("notebook_"), 
      starts_with("language_"),
      starts_with("mlalgs_"),
      starts_with("datascimedia_"),
      starts_with("datavizlib_"),
      starts_with("mltools_"),
      starts_with("compvisionmethods_"),
      starts_with("nlpmethods_"),
      starts_with("mlframeworks"),
      starts_with("cloudcomputeplatform_"),
      starts_with("cloudcomputeproduct_"),
      starts_with("bigdataproduct_"),
      starts_with("mlproduct_"),
      starts_with("automltools_")
      )),
    dummyify
  )
```

Next, we might want to 
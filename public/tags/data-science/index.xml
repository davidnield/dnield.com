<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>data science | David Nield</title>
    <link>/tags/data-science/</link>
      <atom:link href="/tags/data-science/index.xml" rel="self" type="application/rss+xml" />
    <description>data science</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© David Nield, 2020</copyright><lastBuildDate>Wed, 05 Feb 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/img/portrait.jpg</url>
      <title>data science</title>
      <link>/tags/data-science/</link>
    </image>
    
    <item>
      <title>Introduction to the {tidymodels} Machine Learning Ecosystem</title>
      <link>/posts/tidymodels-intro/</link>
      <pubDate>Wed, 05 Feb 2020 00:00:00 +0000</pubDate>
      <guid>/posts/tidymodels-intro/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#stratified-trainingtest-splits&#34;&gt;Stratified training/test splits&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#data-pre-processing&#34;&gt;Data pre-processing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#modeling&#34;&gt;Modeling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#model-evaluation&#34;&gt;Model evaluation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#model-tuning&#34;&gt;Model tuning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;introduction&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;This January I was fortunate enough to attend &lt;a href=&#34;https://blog.rstudio.com/2019/07/15/rstudio-conf-2020/&#34;&gt;rstudio::conf(2020)&lt;/a&gt;, the official conference hosted by &lt;a href=&#34;https://rstudio.com/&#34;&gt;RStudio, PBC&lt;/a&gt; creators of the RStudio IDE and major contributors to the {tidyverse} ecosystem that has become the defacto standard for data importation, manipulation, and visualization in R.&lt;/p&gt;
&lt;p&gt;I could not have asked for a better time for this conference to land in my back yard (San Francisco). As of this writing, I am only 7 months removed from graduating with my Masters. My graduate training left me with a deep understanding of linear models and design-based causal inference, but with little or no training in other types of predictive modeling, unsupervised machine learning, version control, or putting models into production.&lt;/p&gt;
&lt;p&gt;Being able to attend this conference in my first year as a data professional is an enormous blessing and I thank all of the workshop leaders, TAs, session presenters, and conference attendees for creating such a welcoming environment. Every interaction I had at the conference was positive and a learning moment.&lt;/p&gt;
&lt;p&gt;With that, I hope to pay it forward by sharing some of what I learned at the conference.&lt;/p&gt;
&lt;p&gt;The first two days of the conference were divided into 19 workshops, each taught from 9-5 for two days. I chose the Applied Machine Learning workshop in order to fill the gap in my knowledge about machine learning models beyond OLS and logistic regression. Max Kuhn and Davis Vaughn were the two workshop leaders and I knew they were in the process of developing the {tidymodels} ecosystem, which stands to be a successor to their popular {caret} package and promises fill the modeling gap in the {tidyverse} ecosystem. This was an amazing opportunity to both fill in the gaps as well as learn from the package developers themselves.&lt;/p&gt;
&lt;p&gt;My notes for this workshop were incredibly sparse, in no small part because the workshop materials (which are free and available online from &lt;a href=&#34;https://github.com/rstudio-conf-2020/applied-ml&#34;&gt;the workshop’s github repo&lt;/a&gt;) are very detailed.&lt;/p&gt;
&lt;p&gt;Instead of sharing those, I’ve decided to revisit a dataset we worked with during the workshop and present an example of a tidymodels workflow from start to finish, from sample splitting, to data preprocessing, to modeling, to tuning hyperparameters, to packaging it all up into a single workflow object.&lt;/p&gt;
&lt;p&gt;We’ll be using the &lt;a href=&#34;http://jse.amstat.org/v19n3/decock.pdf&#34;&gt;Ames Housing dataset&lt;/a&gt; which contains 81 variables and 2930 observations and our dependent variable is Sale_Price. Obviously, in an actual analysis we would spend much more time exploring this dataset, but for sole purpose of demonstrating the {tidymodels} workflow, we’ll just perform a variety of preprocessing, throw the kitchen sink at the data, then fit a Lasso model and a tuned elastic net model.&lt;/p&gt;
&lt;p&gt;Let’s start by inspecting the data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidymodels)
library(AmesHousing)

ames &amp;lt;- make_ames()

ames %&amp;gt;% 
  head() %&amp;gt;% 
  knitr::kable()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;MS_SubClass&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;MS_Zoning&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Lot_Frontage&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Lot_Area&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Street&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Alley&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Lot_Shape&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Land_Contour&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Utilities&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Lot_Config&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Land_Slope&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Neighborhood&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Condition_1&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Condition_2&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Bldg_Type&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;House_Style&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Overall_Qual&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Overall_Cond&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Year_Built&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Year_Remod_Add&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Roof_Style&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Roof_Matl&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Exterior_1st&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Exterior_2nd&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Mas_Vnr_Type&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Mas_Vnr_Area&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Exter_Qual&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Exter_Cond&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Foundation&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Bsmt_Qual&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Bsmt_Cond&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Bsmt_Exposure&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;BsmtFin_Type_1&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;BsmtFin_SF_1&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;BsmtFin_Type_2&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;BsmtFin_SF_2&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Bsmt_Unf_SF&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Total_Bsmt_SF&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Heating&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Heating_QC&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Central_Air&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Electrical&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;First_Flr_SF&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Second_Flr_SF&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Low_Qual_Fin_SF&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Gr_Liv_Area&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Bsmt_Full_Bath&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Bsmt_Half_Bath&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Full_Bath&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Half_Bath&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Bedroom_AbvGr&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Kitchen_AbvGr&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Kitchen_Qual&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;TotRms_AbvGrd&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Functional&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Fireplaces&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Fireplace_Qu&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Garage_Type&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Garage_Finish&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Garage_Cars&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Garage_Area&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Garage_Qual&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Garage_Cond&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Paved_Drive&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Wood_Deck_SF&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Open_Porch_SF&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Enclosed_Porch&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Three_season_porch&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Screen_Porch&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Pool_Area&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Pool_QC&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Fence&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Misc_Feature&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Misc_Val&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Mo_Sold&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Year_Sold&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Sale_Type&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Sale_Condition&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Sale_Price&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Longitude&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Latitude&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;One_Story_1946_and_Newer_All_Styles&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Residential_Low_Density&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;141&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;31770&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Pave&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;No_Alley_Access&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Slightly_Irregular&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Lvl&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;AllPub&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Corner&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Gtl&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;North_Ames&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Norm&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Norm&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;OneFam&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;One_Story&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Above_Average&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Average&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1960&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1960&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Hip&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;CompShg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;BrkFace&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Plywood&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Stone&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;112&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;CBlock&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Good&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Gd&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;BLQ&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Unf&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;441&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1080&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;GasA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Fair&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Y&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;SBrkr&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1656&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1656&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;7&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typ&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Good&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Attchd&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Fin&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;528&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Partial_Pavement&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;210&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;62&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;No_Pool&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;No_Fence&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;None&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2010&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;WD&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Normal&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;215000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-93.61975&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;42.05403&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;One_Story_1946_and_Newer_All_Styles&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Residential_High_Density&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;80&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;11622&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Pave&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;No_Alley_Access&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Regular&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Lvl&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;AllPub&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Inside&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Gtl&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;North_Ames&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Feedr&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Norm&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;OneFam&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;One_Story&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Average&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Above_Average&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1961&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1961&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Gable&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;CompShg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;VinylSd&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;VinylSd&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;None&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;CBlock&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;No&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Rec&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;LwQ&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;144&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;270&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;882&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;GasA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Y&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;SBrkr&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;896&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;896&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typ&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;No_Fireplace&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Attchd&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Unf&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;730&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Paved&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;140&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;120&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;No_Pool&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Minimum_Privacy&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;None&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2010&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;WD&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Normal&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;105000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-93.61976&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;42.05301&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;One_Story_1946_and_Newer_All_Styles&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Residential_Low_Density&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;81&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;14267&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Pave&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;No_Alley_Access&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Slightly_Irregular&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Lvl&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;AllPub&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Corner&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Gtl&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;North_Ames&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Norm&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Norm&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;OneFam&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;One_Story&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Above_Average&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Above_Average&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1958&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1958&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Hip&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;CompShg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Wd Sdng&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Wd Sdng&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;BrkFace&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;108&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;CBlock&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;No&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;ALQ&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Unf&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;406&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1329&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;GasA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Y&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;SBrkr&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1329&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1329&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Good&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typ&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;No_Fireplace&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Attchd&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Unf&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;312&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Paved&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;393&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;36&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;No_Pool&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;No_Fence&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Gar2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;12500&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2010&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;WD&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Normal&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;172000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-93.61939&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;42.05266&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;One_Story_1946_and_Newer_All_Styles&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Residential_Low_Density&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;93&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;11160&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Pave&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;No_Alley_Access&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Regular&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Lvl&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;AllPub&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Corner&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Gtl&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;North_Ames&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Norm&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Norm&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;OneFam&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;One_Story&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Good&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Average&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1968&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1968&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Hip&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;CompShg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;BrkFace&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;BrkFace&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;None&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Good&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;CBlock&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;No&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;ALQ&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Unf&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1045&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2110&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;GasA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Excellent&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Y&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;SBrkr&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2110&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2110&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Excellent&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;8&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typ&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Attchd&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Fin&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;522&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Paved&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;No_Pool&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;No_Fence&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;None&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2010&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;WD&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Normal&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;244000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-93.61732&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;42.05125&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Two_Story_1946_and_Newer&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Residential_Low_Density&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;74&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;13830&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Pave&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;No_Alley_Access&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Slightly_Irregular&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Lvl&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;AllPub&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Inside&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Gtl&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Gilbert&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Norm&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Norm&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;OneFam&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Two_Story&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Average&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Average&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1997&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1998&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Gable&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;CompShg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;VinylSd&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;VinylSd&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;None&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;PConc&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Good&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;No&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;GLQ&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Unf&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;137&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;928&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;GasA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Good&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Y&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;SBrkr&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;928&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;701&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1629&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typ&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Attchd&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Fin&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;482&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Paved&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;212&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;34&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;No_Pool&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Minimum_Privacy&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;None&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2010&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;WD&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Normal&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;189900&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-93.63893&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;42.06090&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Two_Story_1946_and_Newer&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Residential_Low_Density&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;78&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;9978&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Pave&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;No_Alley_Access&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Slightly_Irregular&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Lvl&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;AllPub&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Inside&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Gtl&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Gilbert&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Norm&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Norm&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;OneFam&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Two_Story&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Above_Average&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Above_Average&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1998&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1998&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Gable&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;CompShg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;VinylSd&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;VinylSd&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;BrkFace&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;20&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;PConc&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;No&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;GLQ&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Unf&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;324&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;926&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;GasA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Excellent&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Y&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;SBrkr&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;926&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;678&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1604&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Good&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;7&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typ&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Good&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Attchd&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Fin&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;470&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Paved&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;360&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;36&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;No_Pool&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;No_Fence&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;None&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2010&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;WD&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Normal&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;195500&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-93.63893&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;42.06078&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Tons of (probably) strongly related variables here. In the real world, we’d probably spend some time thinking about which variables are strictly necessary.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;stratified-trainingtest-splits&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Stratified training/test splits&lt;/h1&gt;
&lt;p&gt;First, let’s split the data. Here, we’ll show one of the neat features of {rsample}, a package within the {tidymodels} ecosystem, which lets us perform stratified sampling on our dependent variable to ensure better balance. We’ll stick with the default split, which is a 75-25 Training-Test split.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## Setting seed
set.seed(1)

## Generate split
ames_split &amp;lt;- initial_split(ames, strata = &amp;quot;Sale_Price&amp;quot;)

## Printing the function gives us &amp;lt;Num Rows in Training Set/Num Rows in Testing Set/Total Num Rows&amp;gt;
ames_split&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;lt;2199/731/2930&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## Calling training() on this object will give us our training set, and calling testing() on it will give us our testing set
ames_train &amp;lt;- training(ames_split)
ames_test &amp;lt;- testing(ames_split)

ames_train %&amp;gt;% 
  head() %&amp;gt;% 
  knitr::kable()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;MS_SubClass&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;MS_Zoning&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Lot_Frontage&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Lot_Area&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Street&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Alley&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Lot_Shape&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Land_Contour&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Utilities&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Lot_Config&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Land_Slope&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Neighborhood&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Condition_1&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Condition_2&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Bldg_Type&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;House_Style&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Overall_Qual&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Overall_Cond&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Year_Built&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Year_Remod_Add&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Roof_Style&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Roof_Matl&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Exterior_1st&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Exterior_2nd&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Mas_Vnr_Type&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Mas_Vnr_Area&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Exter_Qual&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Exter_Cond&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Foundation&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Bsmt_Qual&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Bsmt_Cond&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Bsmt_Exposure&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;BsmtFin_Type_1&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;BsmtFin_SF_1&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;BsmtFin_Type_2&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;BsmtFin_SF_2&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Bsmt_Unf_SF&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Total_Bsmt_SF&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Heating&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Heating_QC&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Central_Air&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Electrical&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;First_Flr_SF&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Second_Flr_SF&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Low_Qual_Fin_SF&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Gr_Liv_Area&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Bsmt_Full_Bath&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Bsmt_Half_Bath&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Full_Bath&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Half_Bath&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Bedroom_AbvGr&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Kitchen_AbvGr&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Kitchen_Qual&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;TotRms_AbvGrd&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Functional&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Fireplaces&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Fireplace_Qu&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Garage_Type&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Garage_Finish&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Garage_Cars&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Garage_Area&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Garage_Qual&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Garage_Cond&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Paved_Drive&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Wood_Deck_SF&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Open_Porch_SF&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Enclosed_Porch&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Three_season_porch&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Screen_Porch&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Pool_Area&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Pool_QC&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Fence&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Misc_Feature&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Misc_Val&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Mo_Sold&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Year_Sold&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Sale_Type&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Sale_Condition&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Sale_Price&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Longitude&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Latitude&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;One_Story_1946_and_Newer_All_Styles&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Residential_Low_Density&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;141&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;31770&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Pave&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;No_Alley_Access&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Slightly_Irregular&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Lvl&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;AllPub&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Corner&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Gtl&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;North_Ames&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Norm&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Norm&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;OneFam&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;One_Story&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Above_Average&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Average&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1960&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1960&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Hip&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;CompShg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;BrkFace&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Plywood&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Stone&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;112&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;CBlock&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Good&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Gd&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;BLQ&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Unf&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;441&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1080&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;GasA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Fair&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Y&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;SBrkr&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1656&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1656&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;7&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typ&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Good&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Attchd&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Fin&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;528&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Partial_Pavement&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;210&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;62&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;No_Pool&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;No_Fence&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;None&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2010&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;WD&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Normal&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;215000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-93.61975&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;42.05403&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;One_Story_1946_and_Newer_All_Styles&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Residential_Low_Density&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;81&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;14267&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Pave&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;No_Alley_Access&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Slightly_Irregular&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Lvl&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;AllPub&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Corner&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Gtl&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;North_Ames&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Norm&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Norm&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;OneFam&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;One_Story&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Above_Average&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Above_Average&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1958&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1958&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Hip&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;CompShg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Wd Sdng&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Wd Sdng&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;BrkFace&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;108&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;CBlock&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;No&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;ALQ&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Unf&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;406&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1329&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;GasA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Y&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;SBrkr&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1329&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1329&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Good&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typ&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;No_Fireplace&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Attchd&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Unf&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;312&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Paved&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;393&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;36&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;No_Pool&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;No_Fence&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Gar2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;12500&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2010&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;WD&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Normal&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;172000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-93.61939&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;42.05266&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;One_Story_1946_and_Newer_All_Styles&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Residential_Low_Density&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;93&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;11160&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Pave&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;No_Alley_Access&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Regular&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Lvl&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;AllPub&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Corner&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Gtl&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;North_Ames&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Norm&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Norm&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;OneFam&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;One_Story&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Good&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Average&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1968&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1968&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Hip&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;CompShg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;BrkFace&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;BrkFace&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;None&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Good&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;CBlock&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;No&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;ALQ&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Unf&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1045&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2110&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;GasA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Excellent&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Y&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;SBrkr&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2110&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2110&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Excellent&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;8&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typ&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Attchd&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Fin&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;522&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Paved&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;No_Pool&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;No_Fence&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;None&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2010&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;WD&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Normal&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;244000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-93.61732&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;42.05125&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Two_Story_1946_and_Newer&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Residential_Low_Density&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;74&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;13830&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Pave&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;No_Alley_Access&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Slightly_Irregular&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Lvl&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;AllPub&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Inside&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Gtl&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Gilbert&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Norm&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Norm&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;OneFam&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Two_Story&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Average&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Average&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1997&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1998&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Gable&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;CompShg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;VinylSd&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;VinylSd&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;None&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;PConc&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Good&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;No&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;GLQ&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Unf&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;137&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;928&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;GasA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Good&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Y&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;SBrkr&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;928&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;701&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1629&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typ&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Attchd&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Fin&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;482&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Paved&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;212&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;34&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;No_Pool&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Minimum_Privacy&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;None&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2010&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;WD&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Normal&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;189900&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-93.63893&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;42.06090&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Two_Story_1946_and_Newer&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Residential_Low_Density&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;78&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;9978&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Pave&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;No_Alley_Access&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Slightly_Irregular&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Lvl&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;AllPub&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Inside&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Gtl&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Gilbert&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Norm&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Norm&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;OneFam&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Two_Story&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Above_Average&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Above_Average&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1998&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1998&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Gable&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;CompShg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;VinylSd&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;VinylSd&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;BrkFace&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;20&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;PConc&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;No&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;GLQ&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Unf&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;324&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;926&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;GasA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Excellent&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Y&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;SBrkr&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;926&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;678&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1604&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Good&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;7&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typ&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Good&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Attchd&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Fin&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;470&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Paved&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;360&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;36&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;No_Pool&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;No_Fence&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;None&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2010&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;WD&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Normal&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;195500&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-93.63893&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;42.06078&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;One_Story_PUD_1946_and_Newer&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Residential_Low_Density&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;41&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4920&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Pave&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;No_Alley_Access&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Regular&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Lvl&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;AllPub&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Inside&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Gtl&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Stone_Brook&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Norm&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Norm&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;TwnhsE&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;One_Story&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Very_Good&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Average&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2001&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2001&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Gable&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;CompShg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;CemntBd&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;CmentBd&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;None&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Good&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;PConc&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Good&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Mn&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;GLQ&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Unf&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;722&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1338&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;GasA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Excellent&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Y&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;SBrkr&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1338&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1338&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Good&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typ&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;No_Fireplace&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Attchd&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Fin&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;582&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Typical&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Paved&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;170&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;No_Pool&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;No_Fence&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;None&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2010&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;WD&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Normal&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;213500&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-93.63379&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;42.06298&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;data-pre-processing&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data pre-processing&lt;/h1&gt;
&lt;p&gt;Now let’s preprocess our data using the {recipes} package, also part of the {tidymodels} ecosystem. To do this, we’ll first specify our formula and our data, and then iterate the preprocessing steps we want. To demonstrate a wide range of things that can be done with {recipes}, let’s first log transform our dependent variable (Sale_Price), then remove variables containing &amp;quot;_Qual&amp;quot; or “Condition” (which are subjective ratings on the part of the appraiser made on or after the sale, we want to predict Sale_Price before sale!), create dummy variables out of our factor variables, center and scale our predictors, then run PCA on the 13 different variables that contain “SF” or “Area” to enough components to capture 75% of the variation in these variables, then remove any near-zero variance predictors. This all sounds like a lot, but the recipes package makes this pre-processing almost self-documenting!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ames_rec &amp;lt;- recipe(
  Sale_Price ~ .,
  data = ames_train
) %&amp;gt;% 
  step_log(Sale_Price, base = 10) %&amp;gt;%
  step_rm(matches(&amp;quot;Qual&amp;quot;), matches(&amp;quot;Cond&amp;quot;)) %&amp;gt;% 
  step_dummy(all_nominal()) %&amp;gt;% 
  step_center(all_predictors()) %&amp;gt;% 
  step_scale(all_predictors()) %&amp;gt;% 
  step_pca(contains(&amp;quot;SF&amp;quot;), contains(&amp;quot;Area&amp;quot;), threshold = .75) %&amp;gt;% 
  step_nzv(all_predictors())

ames_rec&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Data Recipe
## 
## Inputs:
## 
##       role #variables
##    outcome          1
##  predictor         80
## 
## Operations:
## 
## Log transformation on Sale_Price
## Delete terms matches, Qual, matches, Cond
## Dummy variables from all_nominal
## Centering for all_predictors
## Scaling for all_predictors
## No PCA components were extracted.
## Sparse, unbalanced variable filter on all_predictors&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The next step is to prepare or prep() this recipe, which estimates any parameters necessary for the preprocessing steps from the training set to be later applied to other datasets.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ames_rec_trained &amp;lt;- prep(ames_rec, training = ames_train, verbose = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## oper 1 step log [training] 
## oper 2 step rm [training] 
## oper 3 step dummy [training] 
## oper 4 step center [training] 
## oper 5 step scale [training] 
## oper 6 step pca [training] 
## oper 7 step nzv [training] 
## The retained training set is ~ 1.47 Mb  in memory.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ames_rec_trained&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Data Recipe
## 
## Inputs:
## 
##       role #variables
##    outcome          1
##  predictor         80
## 
## Training data contained 2199 data points and no missing data.
## 
## Operations:
## 
## Log transformation on Sale_Price [trained]
## Variables removed Overall_Qual, Exter_Qual, Bsmt_Qual, ... [trained]
## Dummy variables from MS_SubClass, MS_Zoning, Street, Alley, ... [trained]
## Centering for Lot_Frontage, Lot_Area, ... [trained]
## Scaling for Lot_Frontage, Lot_Area, ... [trained]
## PCA extraction with BsmtFin_SF_1, BsmtFin_SF_2, ... [trained]
## Sparse, unbalanced variable filter removed Kitchen_AbvGr, ... [trained]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we can “juice” the prepared recipes, which gives us our preprocessed training set. Lets take a look at our PCA extraction.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ames_rec_trained %&amp;gt;% 
  juice() %&amp;gt;% 
  select(starts_with(&amp;quot;PC&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2,199 x 7
##         PC1    PC2    PC3     PC4     PC5     PC6     PC7
##       &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;
##  1 -1.79     1.20   0.783  0.194   0.120   0.204   2.13  
##  2 -0.625    1.51   0.164 -0.0112  0.0919  1.50    0.256 
##  3 -2.57    -0.201 -0.677  0.723   1.08   -0.455  -0.799 
##  4  0.339    0.932  0.400 -0.230  -0.486   0.819   0.846 
##  5  0.159    0.903  0.385 -0.360  -0.390   1.62    0.510 
##  6 -0.00598 -0.337 -0.603  0.247   0.395  -0.0660 -0.781 
##  7 -0.172   -0.277 -0.689 -0.116  -0.219  -0.772  -0.838 
##  8  0.568   -1.19   0.716 -0.382  -0.347   0.243   0.715 
##  9  0.0123   1.80   0.152 -0.217  -0.0602  2.17   -0.0132
## 10  1.06    -1.55   0.423 -0.211  -0.251  -0.520   0.318 
## # … with 2,189 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Not bad, we’ve reduced 13 variables down to 7. This probably wasn’t the best use case of PCA, but it provides a good example of some advanced preprocessing made simple in {recipes}.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;modeling&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Modeling&lt;/h1&gt;
&lt;p&gt;Now let’s specify our model. We’re going to go with a Lasso model with a penalty of 0.001 using the {parsnip} package.&lt;/p&gt;
&lt;p&gt;To do this, we’re first going to specify our model as a linear regression using linear_reg(), set the mixture proportion to 1 for full L1 regularization (the Lasso), and the penalty to 0.001. Then we’ll set the engine to “glmnet”,as opposed to “lm”, “stan”, “spark”, or “keras” as alternative options. The beauty of {parsnip} is that it unifies the interface for model specifications so that you don’t need to remember dozens of different interfaces for each implementation of a model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ames_lasso &amp;lt;- linear_reg(penalty = 0.001, mixture = 1) %&amp;gt;% 
  set_engine(&amp;quot;glmnet&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we have our recipe and our model, we can create our “workflow”, which packages up our the preprocessing steps and model. Using workflows, we don’t need to go through the prep() and juice() steps we went through earlier when we go to fit our model (I demonstrated prep() and juice() as they can be useful for being able to inspect your pre-processed data as we did earlier).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ames_lasso_wfl &amp;lt;- workflow() %&amp;gt;% 
  add_recipe(ames_rec) %&amp;gt;% 
  add_model(ames_lasso)

ames_lasso_wfl&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ══ Workflow ════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════
## Preprocessor: Recipe
## Model: linear_reg()
## 
## ── Preprocessor ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
## 7 Recipe Steps
## 
## ● step_log()
## ● step_rm()
## ● step_dummy()
## ● step_center()
## ● step_scale()
## ● step_pca()
## ● step_nzv()
## 
## ── Model ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
## Linear Regression Model Specification (regression)
## 
## Main Arguments:
##   penalty = 0.001
##   mixture = 1
## 
## Computational engine: glmnet&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With our workflow designed, fitting our model is as simple as passing our training data and workflow to the fit() function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ames_lasso_fit &amp;lt;- fit(ames_lasso_wfl, ames_train)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And getting predictions is as simple as passing out fitted model and the data we want predictions for to the predict() function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;predict(ames_lasso_fit, ames_train) %&amp;gt;% slice(1:5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 5 x 1
##   .pred
##   &amp;lt;dbl&amp;gt;
## 1  5.32
## 2  5.16
## 3  5.36
## 4  5.30
## 5  5.32&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;model-evaluation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model evaluation&lt;/h1&gt;
&lt;p&gt;How does our model perform on our training set? Let’s find out using metrics from the {yardstick} package. We’ll use three metrics: Root Mean Squared Error (RMSE), R squared, and the concordance correlation coefficient (ccc).&lt;/p&gt;
&lt;p&gt;First we’ll set our three metrics, then we’ll generate predictions, and compare those predictions to the true values within the training set.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;perf_metrics &amp;lt;- metric_set(rmse, rsq, ccc)

perf_lasso &amp;lt;- ames_lasso_fit %&amp;gt;% 
  predict(ames_train) %&amp;gt;% 
  bind_cols(juice(ames_rec_trained)) %&amp;gt;% 
  perf_metrics(truth = Sale_Price, estimate = .pred)

perf_lasso %&amp;gt;% 
  arrange(.metric)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 3
##   .metric .estimator .estimate
##   &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;
## 1 ccc     standard      0.924 
## 2 rmse    standard      0.0657
## 3 rsq     standard      0.861&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Easy peasy! But of course, this is all in-sample. Perhaps we want to know what kind of out-of-sample performance we can expect from our model using cross-validation. {rsample} also makes that easy, so let’s create 10-fold cross-validation sets for evaluating our training set models using vfold_cv(), which defaults to creating 10 folds.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cv_splits &amp;lt;- vfold_cv(ames_train)
cv_splits&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## #  10-fold cross-validation 
## # A tibble: 10 x 2
##    splits           id    
##    &amp;lt;named list&amp;gt;     &amp;lt;chr&amp;gt; 
##  1 &amp;lt;split [2K/220]&amp;gt; Fold01
##  2 &amp;lt;split [2K/220]&amp;gt; Fold02
##  3 &amp;lt;split [2K/220]&amp;gt; Fold03
##  4 &amp;lt;split [2K/220]&amp;gt; Fold04
##  5 &amp;lt;split [2K/220]&amp;gt; Fold05
##  6 &amp;lt;split [2K/220]&amp;gt; Fold06
##  7 &amp;lt;split [2K/220]&amp;gt; Fold07
##  8 &amp;lt;split [2K/220]&amp;gt; Fold08
##  9 &amp;lt;split [2K/220]&amp;gt; Fold09
## 10 &amp;lt;split [2K/219]&amp;gt; Fold10&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we’ll take our workflow and use it to fit 10 models on these 10 splits using the fit_resamples() function from the {tune} package (also a part of the tidymodels ecosystem), as well as tell it to compute the performance metrics we set earlier.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cv_eval &amp;lt;- fit_resamples(ames_lasso_wfl, resamples = cv_splits, metrics = perf_metrics)
cv_eval&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## #  10-fold cross-validation 
## # A tibble: 10 x 4
##    splits           id     .metrics         .notes          
##  * &amp;lt;list&amp;gt;           &amp;lt;chr&amp;gt;  &amp;lt;list&amp;gt;           &amp;lt;list&amp;gt;          
##  1 &amp;lt;split [2K/220]&amp;gt; Fold01 &amp;lt;tibble [3 × 3]&amp;gt; &amp;lt;tibble [0 × 1]&amp;gt;
##  2 &amp;lt;split [2K/220]&amp;gt; Fold02 &amp;lt;tibble [3 × 3]&amp;gt; &amp;lt;tibble [0 × 1]&amp;gt;
##  3 &amp;lt;split [2K/220]&amp;gt; Fold03 &amp;lt;tibble [3 × 3]&amp;gt; &amp;lt;tibble [0 × 1]&amp;gt;
##  4 &amp;lt;split [2K/220]&amp;gt; Fold04 &amp;lt;tibble [3 × 3]&amp;gt; &amp;lt;tibble [0 × 1]&amp;gt;
##  5 &amp;lt;split [2K/220]&amp;gt; Fold05 &amp;lt;tibble [3 × 3]&amp;gt; &amp;lt;tibble [0 × 1]&amp;gt;
##  6 &amp;lt;split [2K/220]&amp;gt; Fold06 &amp;lt;tibble [3 × 3]&amp;gt; &amp;lt;tibble [0 × 1]&amp;gt;
##  7 &amp;lt;split [2K/220]&amp;gt; Fold07 &amp;lt;tibble [3 × 3]&amp;gt; &amp;lt;tibble [0 × 1]&amp;gt;
##  8 &amp;lt;split [2K/220]&amp;gt; Fold08 &amp;lt;tibble [3 × 3]&amp;gt; &amp;lt;tibble [0 × 1]&amp;gt;
##  9 &amp;lt;split [2K/220]&amp;gt; Fold09 &amp;lt;tibble [3 × 3]&amp;gt; &amp;lt;tibble [0 × 1]&amp;gt;
## 10 &amp;lt;split [2K/219]&amp;gt; Fold10 &amp;lt;tibble [3 × 3]&amp;gt; &amp;lt;tibble [0 × 1]&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now let’s compare the in-sample performance we just checked to our cross-validated performance, which is as easy as passing the above fit_samples() object to the collect_metrics() function!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;collect_metrics(cv_eval)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 5
##   .metric .estimator   mean     n std_err
##   &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;   &amp;lt;dbl&amp;gt;
## 1 ccc     standard   0.911     10 0.00767
## 2 rmse    standard   0.0686    10 0.00289
## 3 rsq     standard   0.847     10 0.0155&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;perf_lasso %&amp;gt;% 
  arrange(.metric)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 3
##   .metric .estimator .estimate
##   &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;
## 1 ccc     standard      0.924 
## 2 rmse    standard      0.0657
## 3 rsq     standard      0.861&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Not bad at all! Our cross-validated performance is fairly close to our in-sample performance, it doesn’t seem like we’re overfitting here.&lt;/p&gt;
&lt;p&gt;But I think we can do better. We’ve already used the {tune} package to fit across these resamples, but as the package name suggests, its real power comes in allowing us to easily tune the hyperparameters in our model.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-tuning&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model tuning&lt;/h1&gt;
&lt;p&gt;Recall that we set our regularization penalty to 0.001 and we chose to use L1 regularization. Both those decisions were relatively arbitrary. Let’s use the {tune} package to build an elastic net model by exploring other penalty values and regularization mixtures using cross validation performance to decide what values these parameters should be.&lt;/p&gt;
&lt;p&gt;We’ll start by defining a new model, ames_mixture, which will not take specific specific values for penalty and mixture and will instead leave these as variables to be tuned and swapping out our ames_lasso_wfl with this new workflow.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ames_mixture &amp;lt;- linear_reg(penalty = tune(), mixture = tune()) %&amp;gt;% 
  set_engine(&amp;quot;glmnet&amp;quot;)

ames_mixture_wfl &amp;lt;- update_model(ames_lasso_wfl, ames_mixture)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, we will define a parameter space to search. {tune} allows you to perform either grid search (where the candidate values are pre-defined) or iterative search (ex: Bayesian optimization) where the results of the previous model are used to select the next parameter values to try.&lt;/p&gt;
&lt;p&gt;There are pros/cons to each. A big plus of grid search is that it allows you to take advantage of parallel processing to speed up your search, while iterative search is, by construction, sequential. A big plus of iterative search is that it can quickly rule out areas of parameter space which can be efficient when covering many values of a high dimensional parameter space (where a grid may require many, many models to comfortably cover the entire parameter space, where many of them may turn out to be redundant).&lt;/p&gt;
&lt;p&gt;For this post, we’re going to stick with grid search. The simplest form of grid search uses regular grids, where you provide a vector of values for each parameter and the grid is composed of every possible value combination.&lt;/p&gt;
&lt;p&gt;{tune} provides useful defaults for searching parameter spaces of many common hyperparameters, for example, creating grids for the “penalty” parameter in log-10 space. We can simply specify the parameters, pass these to grid_regular(), and specify that we want 5 levels of penalization and 5 levels of mixture.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mixture_param &amp;lt;- parameters(penalty(), mixture())

regular_grid &amp;lt;- grid_regular(mixture_param, levels = c(5, 5))

regular_grid %&amp;gt;% 
  ggplot(aes(x = mixture, y = penalty)) +
  geom_point() +
  scale_y_log10()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/posts/rstudio-conf/index_files/figure-html/regulargrids-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;{tune} also provides ways to create non-regular grids as well.
* Random grids generated using grid_random() will uniformly sample the parameter space.
* Space-filling designs (SFD) generated using grid_max_entropy() will try to keep candidate values away from one another in order to more efficiently cover the parameter space.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sfd_grid &amp;lt;- grid_max_entropy(mixture_param, size = 25)

sfd_grid&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 25 x 2
##     penalty mixture
##       &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;
##  1 1.21e- 8  0.614 
##  2 1.32e- 1  0.679 
##  3 1.20e-10  0.269 
##  4 3.90e- 9  0.414 
##  5 8.38e- 6  0.0756
##  6 4.02e- 1  0.838 
##  7 5.94e-10  0.504 
##  8 1.83e- 1  0.177 
##  9 3.61e- 3  0.866 
## 10 2.86e- 7  0.856 
## # … with 15 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sfd_grid %&amp;gt;% 
  ggplot(aes(x = mixture, y = penalty)) +
  geom_point() +
  scale_y_log10()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/posts/rstudio-conf/index_files/figure-html/sfdgrids-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For simplicity’s sake, we’ll stick with the regular grid we generated. Let’s start tuning.&lt;/p&gt;
&lt;p&gt;First, we’ll set up our parallelization.&lt;/p&gt;
&lt;p&gt;Now we’re going to create our tuning object, which will take our recipe, our model, our resamples, and our metrics, to fit our 25 models over 10 resamples and compute our performance metrics, then we’ll stop our parallelization.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ames_tune &amp;lt;- tune_grid(
  ames_rec,
  model = ames_mixture,
  resamples = cv_splits,
  grid = regular_grid,
  metrics = perf_metrics
)

stopCluster(cl)

# Naive Lasso performance
collect_metrics(cv_eval)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 5
##   .metric .estimator   mean     n std_err
##   &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;   &amp;lt;dbl&amp;gt;
## 1 ccc     standard   0.911     10 0.00767
## 2 rmse    standard   0.0686    10 0.00289
## 3 rsq     standard   0.847     10 0.0155&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Best tuned models
show_best(ames_tune, &amp;quot;ccc&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 5 x 7
##        penalty mixture .metric .estimator  mean     n std_err
##          &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;      &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;   &amp;lt;dbl&amp;gt;
## 1 0.0000000001    0.25 ccc     standard   0.913    10 0.00760
## 2 0.0000000316    0.25 ccc     standard   0.913    10 0.00760
## 3 0.00001         0.25 ccc     standard   0.913    10 0.00760
## 4 0.0000000001    0.75 ccc     standard   0.913    10 0.00762
## 5 0.0000000316    0.75 ccc     standard   0.913    10 0.00762&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;show_best(ames_tune, &amp;quot;rmse&amp;quot;, maximize = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 5 x 7
##        penalty mixture .metric .estimator   mean     n std_err
##          &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;   &amp;lt;dbl&amp;gt;
## 1 0.0000000001    0    rmse    standard   0.0682    10 0.00235
## 2 0.0000000316    0    rmse    standard   0.0682    10 0.00235
## 3 0.00001         0    rmse    standard   0.0682    10 0.00235
## 4 0.00316         0    rmse    standard   0.0682    10 0.00235
## 5 0.00316         0.25 rmse    standard   0.0684    10 0.00274&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;show_best(ames_tune, &amp;quot;rsq&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 5 x 7
##        penalty mixture .metric .estimator  mean     n std_err
##          &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;      &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;   &amp;lt;dbl&amp;gt;
## 1 0.0000000001    0    rsq     standard   0.849    10  0.0130
## 2 0.0000000316    0    rsq     standard   0.849    10  0.0130
## 3 0.00001         0    rsq     standard   0.849    10  0.0130
## 4 0.00316         0    rsq     standard   0.849    10  0.0130
## 5 0.00316         0.25 rsq     standard   0.848    10  0.0148&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Our results suggest that our original model parameters choices definitely had room for improvement. A much smaller penalty and going with pure L2 regularization seems to perform better on this data. The improvements are relatively modest (RMSE: 0.0686 –&amp;gt; 0.0682, R squared: 0.847 –&amp;gt; 0.849), but when tuning is this easy, why leave money on the table?&lt;/p&gt;
&lt;p&gt;The plot below nicely visualizes the performance of each grid candidate nicely, along with a dotted line to indicate where our original model would’ve been.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;collect_metrics(ames_tune) %&amp;gt;% 
  filter(.metric == &amp;quot;rmse&amp;quot;) %&amp;gt;%
  mutate(mixture = format(mixture)) %&amp;gt;% 
  ggplot(aes(x = penalty, y = mean, col = mixture)) +
  geom_line() +
  geom_point() +
  scale_x_log10() +
  geom_vline(xintercept = 0.001, color = &amp;quot;purple&amp;quot;, lty = &amp;quot;dotted&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/posts/rstudio-conf/index_files/figure-html/tuningplot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now let’s select our best grid candidate, finalize our workflow, and fit our model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;best_mixture &amp;lt;- select_best(ames_tune, metric = &amp;quot;rmse&amp;quot;, maximize = FALSE)
best_mixture&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 2
##        penalty mixture
##          &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;
## 1 0.0000000001       0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ames_mixture_final &amp;lt;- ames_mixture_wfl %&amp;gt;% 
  finalize_workflow(best_mixture) %&amp;gt;% 
  fit(data = ames_train)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And we’re done! We now have a fitted, tuned, regularized mixtured model (albeit, the mixture is 100% L2 regularization, but we got there via tuning!)&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Finally&lt;/em&gt; we get to the fun part. What variables turned out to be the most important in predicting sale price?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tidy_coefs &amp;lt;- ames_mixture_final$fit$fit$fit %&amp;gt;% 
  broom::tidy() %&amp;gt;% 
  filter(term != &amp;quot;(Intercept)&amp;quot;) %&amp;gt;% 
  select(-step, -dev.ratio)

delta &amp;lt;- abs(tidy_coefs$lambda - best_mixture$penalty)
lambda_opt &amp;lt;- tidy_coefs$lambda[which.min(delta)]

label_coefs &amp;lt;- tidy_coefs %&amp;gt;% 
  mutate(abs_estimate = abs(estimate)) %&amp;gt;% 
  filter(abs_estimate &amp;gt;= 0.01) %&amp;gt;% 
  distinct(term) %&amp;gt;% 
  inner_join(tidy_coefs, by = &amp;quot;term&amp;quot;) %&amp;gt;% 
  filter(lambda == lambda_opt)

label_coefs&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 10 x 3
##    term                              estimate lambda
##    &amp;lt;chr&amp;gt;                                &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
##  1 Garage_Cars                         0.0156 0.0139
##  2 Year_Remod_Add                      0.0235 0.0139
##  3 TotRms_AbvGrd                       0.0134 0.0139
##  4 Full_Bath                           0.0124 0.0139
##  5 PC1                                -0.0244 0.0139
##  6 Fireplaces                          0.0121 0.0139
##  7 Central_Air_Y                       0.0121 0.0139
##  8 Bsmt_Full_Bath                      0.0103 0.0139
##  9 Neighborhood_Gilbert               -0.0110 0.0139
## 10 MS_Zoning_Residential_Low_Density   0.0107 0.0139&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tidy_coefs %&amp;gt;% 
  ggplot(aes(x = lambda, y = estimate, group = term, col = term, label = term)) +
  geom_vline(xintercept = lambda_opt, lty = 3) +
  geom_line(alpha = .4) +
  theme(legend.position = &amp;quot;none&amp;quot;) +
  scale_x_log10() +
  ggrepel::geom_text_repel(data = label_coefs)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/posts/rstudio-conf/index_files/figure-html/varimportance-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The above shows the coefficient estimates plotted against lambda, the dotted line indicating the optimal lambda that we selected during our tuning. Nice to see that one of our principal components ended up being important!&lt;/p&gt;
&lt;p&gt;With that all said and done, let’s finally see how our model did against our test set.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ames_mixture_final %&amp;gt;% 
  predict(ames_test) %&amp;gt;% 
  bind_cols(select(ames_test, Sale_Price)) %&amp;gt;% 
  mutate(Sale_Price = log10(Sale_Price)) %&amp;gt;% 
  perf_metrics(truth = Sale_Price, estimate = .pred)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 3
##   .metric .estimator .estimate
##   &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;
## 1 rmse    standard      0.0828
## 2 rsq     standard      0.787 
## 3 ccc     standard      0.877&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Having practiced on this data before, I can say that this is not great performance, but as mentioned before, all of this is just to demonstrate {tidymodels} functionality and workflow.&lt;/p&gt;
&lt;p&gt;There are many, many more features to the {tidymodels} ecosystem and more are continually being developed. I encourage you to explore the vignettes for its composite packages. The parent website is not live as of the writing of this post, but I expect it will be soon. In the mean time, &lt;a href=&#34;https://github.com/tidymodels/tidymodels&#34;&gt;the tidymodels github repository&lt;/a&gt; can point you to the vignettes for each of its composite packages.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>The State of Data Science (Part 2)</title>
      <link>/posts/kaggle-survey/pt-two/</link>
      <pubDate>Tue, 10 Dec 2019 00:00:00 +0000</pubDate>
      <guid>/posts/kaggle-survey/pt-two/</guid>
      <description>&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#demographics&#34;&gt;Demographics&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#the-data-field-today-is-as-disproportionately-male-as-its-ever-been.&#34;&gt;The data field today is as disproportionately male as its ever been.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#no-clear-trend-in-age-composition&#34;&gt;No clear trend in age composition&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#the-increasingly-educated-data-workforce&#34;&gt;The increasingly educated data workforce&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#titles-and-compensation&#34;&gt;Titles and Compensation&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#the-ascendency-of-the-data-scientist-title&#34;&gt;The ascendency of the “data scientist” title&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#data-scientists-compensation-has-increased-even-as-the-title-has-become-more-widespread&#34;&gt;Data scientists’ compensation has increased even as the title has become more widespread&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#languages&#34;&gt;Languages&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#pythons-meteoric-rise&#34;&gt;Python’s meteoric rise&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#wrapping-up&#34;&gt;Wrapping up&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;&lt;p&gt;Kaggle has released the data for their third annual &lt;a href=&#34;https://www.kaggle.com/c/kaggle-survey-2019/overview&#34;&gt;&lt;em&gt;Machine Learning and Data Science Survey&lt;/em&gt;&lt;/a&gt;. I’ve only recently joined the Kaggle platform as I’ve transitioned from academia to private industry, so this seems to be an excellent opportunity to explore the backgrounds of my new data science peers.&lt;/p&gt;
&lt;p&gt;This is the second blog post exploring this data.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://dnield.com/posts/kaggle-survey/pt-one/&#34;&gt;Part 1&lt;/a&gt; explored this year’s survey results.&lt;/p&gt;
&lt;p&gt;Part 2, this post, brings in survey data from the first two years of this annual survey to investigate how the field has changed over the last three years in the United States.&lt;/p&gt;
&lt;p&gt;Note: Because I am based in the United States, as are most of the data science community with which I interact with regularly in-person or on social media, this analysis is limited to the 3085 survey respondents living in the United States.&lt;/p&gt;
&lt;p&gt;Let’s get started!&lt;/p&gt;
&lt;div id=&#34;demographics&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Demographics&lt;/h1&gt;
&lt;div id=&#34;the-data-field-today-is-as-disproportionately-male-as-its-ever-been.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The data field today is as disproportionately male as its ever been.&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;/posts/kaggle-survey/pt-two_files/figure-html/gender-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Perhaps unsurprising given how disportionately male we found the field to be in &lt;a href=&#34;https://dnield.com/posts/kaggle-survey/pt-one/&#34;&gt;part 1&lt;/a&gt;, but there appears to be no trend towards increasing gender diversity among data professionals.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;no-clear-trend-in-age-composition&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;No clear trend in age composition&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;/posts/kaggle-survey/pt-two_files/figure-html/age-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Survey data doesn’t seem to show a clear trend in the age composition of data professionals. This isn’t to say that the composition is stable or unchanging. As always, it should be noted that this survey is a not a random sample of data professionals, but a voluntary response sample survey of Kaggle users, so the composition may change widely based on how Kaggle chooses to promote the survey.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-increasingly-educated-data-workforce&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The increasingly educated data workforce&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;/posts/kaggle-survey/pt-two_files/figure-html/education-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The plot above shows the highest education attainment of respondents to all three years’ surveys. The number of data professionals holding a Master’s degree shocked me in part 1, but the data show that this has been an ongoing trend, while the percent of data professionals holding professional degrees, or only some college education or a high school diploma is near zero. Whether this trend towards a more educated data workforce is due to former Bachelor’s holders seeking and attaining higher education or due to new hires disporportionately coming out of grad school is unclear.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;titles-and-compensation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Titles and Compensation&lt;/h1&gt;
&lt;div id=&#34;the-ascendency-of-the-data-scientist-title&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The ascendency of the “data scientist” title&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;/posts/kaggle-survey/pt-two_files/figure-html/jobtitles-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The proportion of data professionals on Kaggle with the job title “data scientist” has increased 30% relative to 2017: from 30% to 40%. And this doesn’t seem to be simple title changing from former “data analysts”, who also have increased as a proportion of employed Kaggle respondents.&lt;/p&gt;
&lt;p&gt;The greatest decline in relative share of the data workforce are among engineers (which include all titles with “engineer” in their title, from data engineers to SWEs) and researchers (which include all titles with “research” in their title, with the exception of research assistants, which were excluded because these positions are typically not careers).&lt;/p&gt;
&lt;p&gt;More difficult to see here is the relative decline in the “Statistician” title, which started at a barely registerable 3.3%, but has since fallen to 2.4%.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;data-scientists-compensation-has-increased-even-as-the-title-has-become-more-widespread&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data scientists’ compensation has increased even as the title has become more widespread&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;/posts/kaggle-survey/pt-two_files/figure-html/income-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The above plot reports the typical (median) compensation of respondents with each job title. The responses are an ordinal factor so the data is an idomatic median: arrange by the ordered factor, and take the median value. Given a vector of even length and the middle two values are two different categories (e.g. $80,000-89,999 and $90,000-99,999), the lower value will be used.&lt;/p&gt;
&lt;p&gt;The function for this implementation is below, &lt;a href=&#34;https://stackoverflow.com/questions/7925102/idiomatic-method-of-finding-the-median-of-an-ordinal&#34;&gt;with credit to Hong Ooi and Richie Cotton from StackOverflow.&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;median.ordered &amp;lt;- function(x) {
  levs &amp;lt;- levels(x)
  m &amp;lt;- median(as.integer(x), na.rm = TRUE)
  if(floor(m) != m) {
  m &amp;lt;- floor(m)
  }
  ordered(m, labels = levs, levels = seq_along(levs))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;On the whole, the wages of data professionals appear to be on the rise. The median compensation for respondents of every job title except for Engineers appears to be higher in 2019 than it was in 2017 (and median Engineer compensation remaining steady at a very respectable $100,000 to $125,000). Data scientists in particular have broken away to typically make $125,000 to $150,000.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;languages&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Languages&lt;/h1&gt;
&lt;div id=&#34;pythons-meteoric-rise&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Python’s meteoric rise&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;/posts/kaggle-survey/pt-two_files/figure-html/languages-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;About two-thirds of data professionals who program today are using Python, this is a 50% increase relative to the proportion using Python in 2017. Likewise, SQL use has increased 30% during the same time, while R use has remained fairly stable at about 33% and all other languages stable at about 10%.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;wrapping-up&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Wrapping up&lt;/h1&gt;
&lt;p&gt;So there you have it.&lt;/p&gt;
&lt;p&gt;As far as I see here, here are the three big take-aways from Kaggle’s three years of survey results:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Unfortunately, the data workforce does not appear to becoming any more gender diverse than it was in 2017.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;“Data scientist” as a title has become extremely widespread, and in spite of this proliference, is as highly paid as ever.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Python and SQL are becoming universal, but not at the expense of other languages.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The State of Data Science (Part 1)</title>
      <link>/posts/kaggle-survey/pt-one/</link>
      <pubDate>Tue, 19 Nov 2019 00:00:00 +0000</pubDate>
      <guid>/posts/kaggle-survey/pt-one/</guid>
      <description>&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#demographics&#34;&gt;Demographics&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#three-quarters-of-data-professionals-are-men&#34;&gt;Three-quarters of data professionals are men&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#data-professionals-are-fairly-young&#34;&gt;Data professionals are fairly young&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#underrepresentation-of-women-persists-across-cohort&#34;&gt;Underrepresentation of women persists across cohort&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#the-majority-of-data-professionals-have-an-advanced-degree&#34;&gt;The majority of data professionals have an advanced degree&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#titles-compensation-experience-and-roles&#34;&gt;Titles, Compensation, Experience, and Roles&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#my-name-is-scientist-data-scientist&#34;&gt;“My Name is Scientist, Data Scientist”&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#data-scientists-make-the-big-bucks&#34;&gt;Data scientists make the big bucks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#data-professionals-team-sizes-are-highly-bimodal&#34;&gt;Data professionals’ team sizes are highly bimodal&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#data-professionals-most-common-important-role-is-informing-business-decisions&#34;&gt;Data professionals’ most common important role is informing business decisions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#languages-and-tools&#34;&gt;Languages and Tools&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#python-is-king&#34;&gt;Python is King&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#the-majority-of-data-professionals-on-kaggle-are-relatively-new-to-writing-code-for-data-analysis.&#34;&gt;The majority of data professionals on Kaggle are relatively new to writing code for data analysis.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#theres-a-shocking-amount-of-experienced-machine-learning-practitioners&#34;&gt;There’s a shocking amount of experienced machine learning practitioners!&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#thats-all-folks&#34;&gt;That’s all, folks!&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;&lt;p&gt;Kaggle has released the data for their third annual &lt;a href=&#34;https://www.kaggle.com/c/kaggle-survey-2019/overview&#34;&gt;&lt;em&gt;Machine Learning and Data Science Survey&lt;/em&gt;&lt;/a&gt;. I’ve only recently joined the Kaggle platform as I’ve transitioned from academia to private industry, so this seems to be an excellent opportunity to explore the backgrounds of my new data science peers.&lt;/p&gt;
&lt;p&gt;This is the first of the two part series exploring this data.&lt;/p&gt;
&lt;p&gt;Today we will explore this year’s survey results.&lt;/p&gt;
&lt;p&gt;Part 2 will bring in survey data from the first two years of this annual survey to investigate how the field has changed over the last three years in the United States.&lt;/p&gt;
&lt;p&gt;Note: Because I am based in the United States, as are most of the data science community with which I interact with regularly in-person or on social media, this analysis is limited to the 3085 survey respondents living in the United States.&lt;/p&gt;
&lt;p&gt;Let’s get started!&lt;/p&gt;
&lt;div id=&#34;demographics&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Demographics&lt;/h1&gt;
&lt;div id=&#34;three-quarters-of-data-professionals-are-men&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Three-quarters of data professionals are men&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;/posts/kaggle-survey/pt-one_files/figure-html/gender-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I’m not surprised that the majority of data professionals are men, but I was shocked at how stark the split is. At Callisto (my company), our R&amp;amp;D team (which includes analysts and engineers) is almost exactly evenly split, which I knew is an outlier in the Data industry, but I didn’t realize by how much.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;data-professionals-are-fairly-young&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data professionals are fairly young&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;/posts/kaggle-survey/pt-one_files/figure-html/age-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As one might expect from a field that itself is relatively young, data professionals themselves are fairly young, with the modal data professional being age 25 to 29. I, myself, am turning 25 next month, so I’m pretty much modal here.&lt;/p&gt;
&lt;p&gt;Be wary here, as the bin widths of these ages are changing across the x-axis. Unfortunately, this is as specific as the data get.&lt;/p&gt;
&lt;p&gt;One alternative explanation for these data is that many Kagglers are early career data professionals who use or used Kaggle to build a professional portfolio for the job market. Older data professionals may be underrepresented here.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;underrepresentation-of-women-persists-across-cohort&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Underrepresentation of women persists across cohort&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;/posts/kaggle-survey/pt-one_files/figure-html/agebygender-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I expected there to be underrepresentation of women in the Data industry, but I would’ve expected the divide to be much less stark among younger cohorts of data professionals than older ones. The above plots show that this doesn’t appear to be the case.&lt;/p&gt;
&lt;p&gt;The top panel shows a representation of a contingency table, that is, the percent of respondents that identify as male or female that fall into each age category. Women are clearly underrepresented at every age.&lt;/p&gt;
&lt;p&gt;The bottom two panels break this plot into its marginals. The left panel shows the percent of data professionals of each gender that fall into each age category. It shows the same broad pattern for both men and women, with female data professionals skewing just a bit younger. The right shows the gender split of each age category. It shows that the gender split of data professionals hovers around 75% for almost every cohort except those over 60 years old. Clearly the underrepresentation of women in the data industry is not something that will go away as a result of retiring older cohorts.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-majority-of-data-professionals-have-an-advanced-degree&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The majority of data professionals have an advanced degree&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;/posts/kaggle-survey/pt-one_files/figure-html/education-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Unsurprisingly, data professionals are an educated bunch. Surprising to me, however, was the number of Master’s degree holders and the relative sparsity of PhDs and professional degree holders. Coming from academia, I expected the data industry to be primarily comprised of: 1) non-CS Bachelor’s and MBA holders building reports and dashboards, 2) CS/Engineering Bachelor’s holders building and maintaining data infrastructure, and 3) PhDs who left academia due to the job market or lured by mobility and money in private industry. I did not expect to see that &lt;em&gt;half&lt;/em&gt; of all data professionals are Master’s holders!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;titles-compensation-experience-and-roles&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Titles, Compensation, Experience, and Roles&lt;/h1&gt;
&lt;div id=&#34;my-name-is-scientist-data-scientist&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;“My Name is Scientist, Data Scientist”&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;/posts/kaggle-survey/pt-one_files/figure-html/jobtitle-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Another shocking finding to me was sheer amount of data scientists in the survey relative to all other roles. I have a pretty strong Bayesian prior that there aren’t 2.5x as many data scientists as there are data analysts in the data industry, so this is definitely a reality check that this survey should &lt;em&gt;not&lt;/em&gt; be considered a representative survey of the industry.&lt;/p&gt;
&lt;p&gt;Additionally, the sheer number of students represented in the survey seems consistent with my hypothesis that many Kagglers may be on the platform to build up an data analysis portfolio for the job market. The percentage (3.6%) of “Not Employed” respondents seems consistent with this as well.&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; I suspect the true unemployment rate for data professionals is, in reality, lower than the national unemployment rate (3.7% as of this writing), not almost identical to it.&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;data-scientists-make-the-big-bucks&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data scientists make the big bucks&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;/posts/kaggle-survey/pt-one_files/figure-html/compensation-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The 2019 Kaggle ML &amp;amp; DS Survey reports annual compensation in brackets. I’m interested in the median income of data professionals by title, but obviously taking the median of categorical data isn’t something R takes kindly to!&lt;/p&gt;
&lt;p&gt;However, since this factor is ordinal, it is possible to take an idomatic median: just arrange by the ordered factor, and take the median value. The hitch is when you have a vector of even length and the middle two values are two different categories (e.g. $80,000-89,999 and $90,000-99,999). Strictly speaking, I prefer to just take the cutpoint between the two categories ($90,000) or an interval with the cutpoint as the center point as the value. However, for this quick and dirty exploration, I’m just going to take the lower of the two categories as the winner of the tie.&lt;/p&gt;
&lt;p&gt;The function for this implementation is below, &lt;a href=&#34;https://stackoverflow.com/questions/7925102/idiomatic-method-of-finding-the-median-of-an-ordinal&#34;&gt;with credit to Hong Ooi and Richie Cotton from StackOverflow.&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;median.ordered &amp;lt;- function(x) {
  levs &amp;lt;- levels(x)
  m &amp;lt;- median(as.integer(x), na.rm = TRUE)
  if(floor(m) != m) {
  m &amp;lt;- floor(m)
  }
  ordered(m, labels = levs, levels = seq_along(levs))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The above plot shows the median income of each job title computed in this way, preserving the ordering of job titles by their frequency in the previous plot. Students and Unemployed respondents were not asked for their annual compensation, but in order to preserve the frequency order they are represented here.&lt;/p&gt;
&lt;p&gt;Clearly, as a Data Analyst, I’m in the wrong job! Data Analysts and Business Analysts are tied for last, with the median analysts making $80,000 to $89,999 annually, while Data Scientists make the big bucks, with the median data scientist making $125,000 to $149,999 annually.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;data-professionals-team-sizes-are-highly-bimodal&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data professionals’ team sizes are highly bimodal&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;/posts/kaggle-survey/pt-one_files/figure-html/teamsize-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Almost 40% of business have data science teams of less than five while another 40% have data science teams of over twenty! That’s quite the bimodality. Hard to think of an explanation about why this would be, although my intuition is that this is due to how young the field is combined with restricted&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;data-professionals-most-common-important-role-is-informing-business-decisions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data professionals’ most common important role is informing business decisions&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;/posts/kaggle-survey/pt-one_files/figure-html/roles-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I’m a bit disappointed in the possible multiple-choice answers here. Machine learning spans three of the five possible roles, however building, improving, and researching machine learning models, I would argue, is something that more generalist data professionals engage in, even when they have the skills, meanwhile “influence business decisions” and “build or run data infrastructure” are so broad as to be almost uninformative, while the distinction between “building” and “improving” ML models seems much less useful than knowing the type of models being used (predictive or forecasting models vs classification models vs generative models).&lt;/p&gt;
&lt;p&gt;I would have liked to see response options broken out into “building and/or maintaining periodic reports or dashboards”, “experimental design”, “forecasting”, etc.&lt;/p&gt;
&lt;p&gt;Nonetheless, the key finding here is that the most common important role of data professionals appears to be informing business decisions.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;languages-and-tools&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Languages and Tools&lt;/h1&gt;
&lt;div id=&#34;python-is-king&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Python is King&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;/posts/kaggle-survey/pt-one_files/figure-html/languages-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Unfortunately, Julia wasn’t offered as an option on this survey, and I’m not sure why. It was asked about in previous iterations of this survey, and Julia has continued to mature as a language.&lt;/p&gt;
&lt;p&gt;Much to my chagrin as an R user, Python dominates as the most coding language used by data professionals. SQL comes next, followed by R, then Java, followed by a long tail of other languages.&lt;/p&gt;
&lt;p&gt;I’m surprised by the proliference of Java. I’ve always thought of the modal data professional toolkit as: SQL for querying databases, R/Python for modeling and prototyping, and C++ for production code. I don’t know of any data scientists using Java. I’ll be curious to dig into this more.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-majority-of-data-professionals-on-kaggle-are-relatively-new-to-writing-code-for-data-analysis.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The majority of data professionals on Kaggle are relatively new to writing code for data analysis.&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;/posts/kaggle-survey/pt-one_files/figure-html/coding_experience-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The majority of data professionals have less than five years of experience writing code for data analysis, which is consistent with the broadly young age distribution of data professionals. Like with age, my four years experience writing code for analysis make me pretty modal here as well.&lt;/p&gt;
&lt;p&gt;I’m curious about the typical experience levels of the job titles earlier. Let’s taking the same idiomatic median we used earlier to compute median income to see what the median experience category is for each job title.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/posts/kaggle-survey/pt-one_files/figure-html/codingexpbytitle-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Perhaps unsurprisingly, data scientists, research scientists, data engineers, and statisticians clock in as the most experience writing code to analyze data, while students are the least experienced. It appears that my level of coding experience is typical for my job title among Kagglers.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;theres-a-shocking-amount-of-experienced-machine-learning-practitioners&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;There’s a shocking amount of experienced machine learning practitioners!&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;/posts/kaggle-survey/pt-one_files/figure-html/mlexp-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;First, it should be noted that this question was only asked of those that said they had experience coding data analysis. I should note that I &lt;em&gt;believe&lt;/em&gt; that the “&amp;lt; 1 years” category includes data professionals with less than a year of ML experience with those with none. Kaggle offered the survey schema and question wording for this survey, but did not provide a list of all of the possible responses to each multiple-choice question. In previous years of this survey, “I have never studied machine learning but plan to learn in the future” was an offered response option. However, not a single response among the over 17,000 respondents in the 2019 survey indicates no experience, which seems unlikely to happen if no experience was an option.&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt; It seems more likely that “less than 1 years experience” captures both respondents with no experience and those with less than some number of months experience.&lt;/p&gt;
&lt;p&gt;Nonetheless, even discounting this to the maximum extent possible (that all &amp;lt; 1 year responses indicate zero experience), the amount of ML experience in the community surprised me quite a bit.&lt;/p&gt;
&lt;p&gt;First of all, there’s no reason ex-ante that data analysis should entail fitting a model to data. Plenty of (I’d argue most) excellent analysis can be done through simple graphs and tables so there’s no strong reason to need it.&lt;/p&gt;
&lt;p&gt;Secondly, I would be surprised if every single Kaggler has the training (formal or informal) necessary for the application and interpretation of even simple machine learning models such as linear regression, nevermind more complex “black box” models like neural networks and support vector machines.&lt;/p&gt;
&lt;p&gt;Thirdly, the very definition of what counts as “machine learning” is contentious. Does linear regression even count? My gut says no, only the related linear model selection algorithms like MARS, lasso, and ridge regression count, but linear regression is considered to be a machine learning algorithm by many others&lt;a href=&#34;#fn4&#34; class=&#34;footnote-ref&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt; and is listed as a machine learning algorithm in this survey. By my own definition, I only have 2 years of machine learning experience, but if linear regression counts then I have 4 years experience, which, according this data, makes me a veteran!&lt;/p&gt;
&lt;p&gt;Luckily, another question asks respondents which machine learning algorithms they use on a regular basis, helping us to dig into this a bit more.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/posts/kaggle-survey/pt-one_files/figure-html/mlalgs-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As expected, linear and logistic regression top the charts as the algorithms used on a regular basis by the most data professionals. Still, I’m surprised by how popular decision tree models and gradient boosting machines are. Perhaps a testament to how easy out-of-the-box versions of these algorithms have become to deploy due to the maturity of packages like sklearn, xgboost, caret, ranger, randomForest, among others.&lt;/p&gt;
&lt;p&gt;The ecology of machine learning platforms has developed to the degree that the practioners dilemma seems to be deciding &lt;em&gt;which&lt;/em&gt; of the numerous high quality frameworks and packages to use.&lt;/p&gt;
&lt;p&gt;Luckily, we have data on this as well!&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/posts/kaggle-survey/pt-one_files/figure-html/mlframeworks-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;With Python dominance comes sklearn dominance. Luckily for R users, TensorFlow and Keras remain the dominant framework for building neural networks. I expect PyTorch to continue to grow, but if it ever overtakes TensorFlow, I expect R implementations and interfaces to have matured by then.&lt;/p&gt;
&lt;p&gt;I also expect that the &lt;a href=&#34;https://www.tidyverse.org/blog/2018/08/tidymodels-0-0-1/&#34;&gt;&lt;em&gt;tidymodels&lt;/em&gt;&lt;/a&gt; framework, developed by Max Kuhn, the author of “caret”, and other authors in the tidyverse to succeed &lt;em&gt;caret&lt;/em&gt; to begin emerging as a leading machine learning framework for R users in 2020 as the ecosystem continues to mature.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;thats-all-folks&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;That’s all, folks!&lt;/h1&gt;
&lt;p&gt;As mentioned before, Part 2 of this series will be a comparing the results of this survey to the results of the two prior annual Kaggle surveys to see how the industry has changed over the last three years.&lt;/p&gt;
&lt;p&gt;Expect that post whenever I get around to cleaning those (far larger, in terms of questionnaire length) survey datasets.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Retired respondents are not counted as Not Employed here, as they were instructed to choose the most similar to the one they held most recently&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;Some readers with an economics background may, rightfully, chime in that some frictional unemployment may actually be a sign of a healthy labor market that favors workers, as people may quit jobs knowing they’ll get a better job shortly, although I would argue that this is still consistent with the point that Kagglers are on the platform, in part, as a signal to employers&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;Even if it’s true that every single respondent has some experience with machine learning, even a miniscule amount of measurement error should result in at least one response indicating none&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;Including Hastie et al in &lt;em&gt;Elements of Statistical Learning&lt;/em&gt;, one of the many bibles on the topic&lt;a href=&#34;#fnref4&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
